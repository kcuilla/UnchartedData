[
  {
    "path": "posts/2022-09-30-interactive-tooltip-tables/",
    "title": "Interactive Tooltip Tables",
    "description": "How to include tables in your {ggiraph} tooltips.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2022-09-30",
    "categories": [
      "tutorial",
      "data visualization",
      "ggplot2",
      "purrr"
    ],
    "contents": "\r\nAbout\r\nIn this tutorial, I’ll show you how to add tables to interactive {ggiraph} tooltips like the one I created below using the {kableExtra} and {gt}/{gtExtras} packages.\r\n\r\n\r\nShow code\r\n\r\nknitr::include_graphics(\"https://raw.githubusercontent.com/kcuilla/USgasprices/main/imgs/gas_map_demo.gif\")\r\n\r\n\r\n\r\nSource: US Gas Prices Shiny App\r\nAs an added bonus, I’ll show you a trick on how to apply conditional formatters from {gtExtras} to the tooltips by parsing the raw HTML content of the table.\r\nInteractive Tooltips\r\n{ggiraph} is an amazing package that makes any {ggplot2} graphic interactive.\r\nThe example below, which comes from the package site, shows how easy it is to make a {ggplot2} interactive:\r\n\r\n\r\nShow code\r\n\r\nlibrary(ggplot2)\r\nlibrary(ggiraph)\r\nlibrary(dplyr)\r\n\r\n# load mtcars dataset\r\ndata <- mtcars %>% dplyr::select(qsec, wt, disp, mpg, hp, cyl)\r\ndata$car <- row.names(data)\r\n\r\n# default ggiraph tooltip\r\ngg_point <- ggplot2::ggplot(data = data) +\r\n  ggiraph::geom_point_interactive(aes(\r\n    x = wt,\r\n    y = qsec,\r\n    color = disp,\r\n    data_id = car,\r\n    # display car in the tooltip\r\n    tooltip = car\r\n  )) +\r\n  ggplot2::theme_minimal()\r\n\r\n# pass through girafe to activate interactivity\r\nggiraph::girafe(ggobj = gg_point)\r\n\r\n\r\n\r\nIf you hover your mouse over the data points on the chart, you will see the car name within the tooltip. But what if we wanted to add more info to the tooltip such as the car’s mpg, hp, and number of cyl? How would we do that?\r\nWell if you’ve made it this far, you probably already know the answer: tables! How do we do that exactly? I’ll explain step-by-step below.\r\nUsing {kableExtra} to create the table for the tooltip\r\nThe first thing we need to do is to design our table. In this example, we’ll use the {kableExtra} package to build the table.\r\nLater, I will also show you how to use the {gt} and {gtExtras} packages.\r\nHere’s a preview of a simple table built with {kableExtra} with the columns that we need:\r\n\r\n\r\nShow code\r\n\r\nlibrary(kableExtra)\r\nlibrary(dplyr)\r\n\r\ntable <- data %>%\r\n  dplyr::select(car, mpg, hp, cyl) %>% \r\n  kableExtra::kbl(row.names = FALSE)\r\n\r\ntable\r\n\r\n\r\ncar\r\n\r\n\r\nmpg\r\n\r\n\r\nhp\r\n\r\n\r\ncyl\r\n\r\n\r\nMazda RX4\r\n\r\n\r\n21.0\r\n\r\n\r\n110\r\n\r\n\r\n6\r\n\r\n\r\nMazda RX4 Wag\r\n\r\n\r\n21.0\r\n\r\n\r\n110\r\n\r\n\r\n6\r\n\r\n\r\nDatsun 710\r\n\r\n\r\n22.8\r\n\r\n\r\n93\r\n\r\n\r\n4\r\n\r\n\r\nHornet 4 Drive\r\n\r\n\r\n21.4\r\n\r\n\r\n110\r\n\r\n\r\n6\r\n\r\n\r\nHornet Sportabout\r\n\r\n\r\n18.7\r\n\r\n\r\n175\r\n\r\n\r\n8\r\n\r\n\r\nValiant\r\n\r\n\r\n18.1\r\n\r\n\r\n105\r\n\r\n\r\n6\r\n\r\n\r\nDuster 360\r\n\r\n\r\n14.3\r\n\r\n\r\n245\r\n\r\n\r\n8\r\n\r\n\r\nMerc 240D\r\n\r\n\r\n24.4\r\n\r\n\r\n62\r\n\r\n\r\n4\r\n\r\n\r\nMerc 230\r\n\r\n\r\n22.8\r\n\r\n\r\n95\r\n\r\n\r\n4\r\n\r\n\r\nMerc 280\r\n\r\n\r\n19.2\r\n\r\n\r\n123\r\n\r\n\r\n6\r\n\r\n\r\nMerc 280C\r\n\r\n\r\n17.8\r\n\r\n\r\n123\r\n\r\n\r\n6\r\n\r\n\r\nMerc 450SE\r\n\r\n\r\n16.4\r\n\r\n\r\n180\r\n\r\n\r\n8\r\n\r\n\r\nMerc 450SL\r\n\r\n\r\n17.3\r\n\r\n\r\n180\r\n\r\n\r\n8\r\n\r\n\r\nMerc 450SLC\r\n\r\n\r\n15.2\r\n\r\n\r\n180\r\n\r\n\r\n8\r\n\r\n\r\nCadillac Fleetwood\r\n\r\n\r\n10.4\r\n\r\n\r\n205\r\n\r\n\r\n8\r\n\r\n\r\nLincoln Continental\r\n\r\n\r\n10.4\r\n\r\n\r\n215\r\n\r\n\r\n8\r\n\r\n\r\nChrysler Imperial\r\n\r\n\r\n14.7\r\n\r\n\r\n230\r\n\r\n\r\n8\r\n\r\n\r\nFiat 128\r\n\r\n\r\n32.4\r\n\r\n\r\n66\r\n\r\n\r\n4\r\n\r\n\r\nHonda Civic\r\n\r\n\r\n30.4\r\n\r\n\r\n52\r\n\r\n\r\n4\r\n\r\n\r\nToyota Corolla\r\n\r\n\r\n33.9\r\n\r\n\r\n65\r\n\r\n\r\n4\r\n\r\n\r\nToyota Corona\r\n\r\n\r\n21.5\r\n\r\n\r\n97\r\n\r\n\r\n4\r\n\r\n\r\nDodge Challenger\r\n\r\n\r\n15.5\r\n\r\n\r\n150\r\n\r\n\r\n8\r\n\r\n\r\nAMC Javelin\r\n\r\n\r\n15.2\r\n\r\n\r\n150\r\n\r\n\r\n8\r\n\r\n\r\nCamaro Z28\r\n\r\n\r\n13.3\r\n\r\n\r\n245\r\n\r\n\r\n8\r\n\r\n\r\nPontiac Firebird\r\n\r\n\r\n19.2\r\n\r\n\r\n175\r\n\r\n\r\n8\r\n\r\n\r\nFiat X1-9\r\n\r\n\r\n27.3\r\n\r\n\r\n66\r\n\r\n\r\n4\r\n\r\n\r\nPorsche 914-2\r\n\r\n\r\n26.0\r\n\r\n\r\n91\r\n\r\n\r\n4\r\n\r\n\r\nLotus Europa\r\n\r\n\r\n30.4\r\n\r\n\r\n113\r\n\r\n\r\n4\r\n\r\n\r\nFord Pantera L\r\n\r\n\r\n15.8\r\n\r\n\r\n264\r\n\r\n\r\n8\r\n\r\n\r\nFerrari Dino\r\n\r\n\r\n19.7\r\n\r\n\r\n175\r\n\r\n\r\n6\r\n\r\n\r\nMaserati Bora\r\n\r\n\r\n15.0\r\n\r\n\r\n335\r\n\r\n\r\n8\r\n\r\n\r\nVolvo 142E\r\n\r\n\r\n21.4\r\n\r\n\r\n109\r\n\r\n\r\n4\r\n\r\n\r\nIf we replace ‘car’ with our table in the tooltip option of ggiraph::geom_point_interactive(), the full table will appear when hovering over each point on the plot.\r\nOur table is showing within the tooltip, but this isn’t quite what we want. Instead, we want to show the values that are relevant for each specific car.\r\n\r\n\r\nShow code\r\n\r\ngg_point <- ggplot2::ggplot(data = data) +\r\n  ggiraph::geom_point_interactive(aes(\r\n    x = wt,\r\n    y = qsec,\r\n    color = disp,\r\n    data_id = car,\r\n    tooltip = table\r\n  )) +\r\n  ggplot2::theme_minimal()\r\n\r\ngirafe(ggobj = gg_point)\r\n\r\n\r\n\r\nTo fix this, we need to create a column within our dataset that contains a table for each row. We can write a function that will loop through each car and add its corresponding data from the mpg, hp, and cyl columns using the {purrr} package.\r\nCreating a table for each observation\r\nWe’ll start by creating a simple function that filters our dataset based on the car, selects the columns we need for our table, and builds the table with {kableExtra}. This is the same code we used to build our tables in the previous section, the only difference is that we’re adding a parameter to filter on the car before building our table.\r\n\r\n\r\nShow code\r\n\r\nmake_table <- function(name) {\r\n  data %>%\r\n    # filter by car name\r\n    dplyr::filter(car == name) %>% \r\n    dplyr::select(car, mpg, hp, cyl) %>% \r\n    kableExtra::kbl(row.names = FALSE) \r\n}\r\n\r\n\r\nNow that we have our function, we can use purrr::map() to iterate over each car in the dataset and store the tables in a column called ‘table’.\r\nWhen we look at the updated dataset, we can see that the table column contains the raw HTML that is used to create the tables in the {kableExtra} package.\r\n\r\n\r\nShow code\r\n\r\nlibrary(purrr)\r\n\r\ndf <- data %>% \r\n  dplyr::mutate(table = purrr::map(car, make_table)) %>% \r\n  dplyr::select(car, qsec, wt, disp, table)\r\n\r\nhead(df)\r\n\r\n                                car  qsec    wt disp\r\nMazda RX4                 Mazda RX4 16.46 2.620  160\r\nMazda RX4 Wag         Mazda RX4 Wag 17.02 2.875  160\r\nDatsun 710               Datsun 710 18.61 2.320  108\r\nHornet 4 Drive       Hornet 4 Drive 19.44 3.215  258\r\nHornet Sportabout Hornet Sportabout 17.02 3.440  360\r\nValiant                     Valiant 20.22 3.460  225\r\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          table\r\nMazda RX4                   <table>\\n <thead>\\n  <tr>\\n   <th style=\"text-align:left;\"> car <\/th>\\n   <th style=\"text-align:right;\"> mpg <\/th>\\n   <th style=\"text-align:right;\"> hp <\/th>\\n   <th style=\"text-align:right;\"> cyl <\/th>\\n  <\/tr>\\n <\/thead>\\n<tbody>\\n  <tr>\\n   <td style=\"text-align:left;\"> Mazda RX4 <\/td>\\n   <td style=\"text-align:right;\"> 21 <\/td>\\n   <td style=\"text-align:right;\"> 110 <\/td>\\n   <td style=\"text-align:right;\"> 6 <\/td>\\n  <\/tr>\\n<\/tbody>\\n<\/table>\r\nMazda RX4 Wag           <table>\\n <thead>\\n  <tr>\\n   <th style=\"text-align:left;\"> car <\/th>\\n   <th style=\"text-align:right;\"> mpg <\/th>\\n   <th style=\"text-align:right;\"> hp <\/th>\\n   <th style=\"text-align:right;\"> cyl <\/th>\\n  <\/tr>\\n <\/thead>\\n<tbody>\\n  <tr>\\n   <td style=\"text-align:left;\"> Mazda RX4 Wag <\/td>\\n   <td style=\"text-align:right;\"> 21 <\/td>\\n   <td style=\"text-align:right;\"> 110 <\/td>\\n   <td style=\"text-align:right;\"> 6 <\/td>\\n  <\/tr>\\n<\/tbody>\\n<\/table>\r\nDatsun 710                <table>\\n <thead>\\n  <tr>\\n   <th style=\"text-align:left;\"> car <\/th>\\n   <th style=\"text-align:right;\"> mpg <\/th>\\n   <th style=\"text-align:right;\"> hp <\/th>\\n   <th style=\"text-align:right;\"> cyl <\/th>\\n  <\/tr>\\n <\/thead>\\n<tbody>\\n  <tr>\\n   <td style=\"text-align:left;\"> Datsun 710 <\/td>\\n   <td style=\"text-align:right;\"> 22.8 <\/td>\\n   <td style=\"text-align:right;\"> 93 <\/td>\\n   <td style=\"text-align:right;\"> 4 <\/td>\\n  <\/tr>\\n<\/tbody>\\n<\/table>\r\nHornet 4 Drive       <table>\\n <thead>\\n  <tr>\\n   <th style=\"text-align:left;\"> car <\/th>\\n   <th style=\"text-align:right;\"> mpg <\/th>\\n   <th style=\"text-align:right;\"> hp <\/th>\\n   <th style=\"text-align:right;\"> cyl <\/th>\\n  <\/tr>\\n <\/thead>\\n<tbody>\\n  <tr>\\n   <td style=\"text-align:left;\"> Hornet 4 Drive <\/td>\\n   <td style=\"text-align:right;\"> 21.4 <\/td>\\n   <td style=\"text-align:right;\"> 110 <\/td>\\n   <td style=\"text-align:right;\"> 6 <\/td>\\n  <\/tr>\\n<\/tbody>\\n<\/table>\r\nHornet Sportabout <table>\\n <thead>\\n  <tr>\\n   <th style=\"text-align:left;\"> car <\/th>\\n   <th style=\"text-align:right;\"> mpg <\/th>\\n   <th style=\"text-align:right;\"> hp <\/th>\\n   <th style=\"text-align:right;\"> cyl <\/th>\\n  <\/tr>\\n <\/thead>\\n<tbody>\\n  <tr>\\n   <td style=\"text-align:left;\"> Hornet Sportabout <\/td>\\n   <td style=\"text-align:right;\"> 18.7 <\/td>\\n   <td style=\"text-align:right;\"> 175 <\/td>\\n   <td style=\"text-align:right;\"> 8 <\/td>\\n  <\/tr>\\n<\/tbody>\\n<\/table>\r\nValiant                     <table>\\n <thead>\\n  <tr>\\n   <th style=\"text-align:left;\"> car <\/th>\\n   <th style=\"text-align:right;\"> mpg <\/th>\\n   <th style=\"text-align:right;\"> hp <\/th>\\n   <th style=\"text-align:right;\"> cyl <\/th>\\n  <\/tr>\\n <\/thead>\\n<tbody>\\n  <tr>\\n   <td style=\"text-align:left;\"> Valiant <\/td>\\n   <td style=\"text-align:right;\"> 18.1 <\/td>\\n   <td style=\"text-align:right;\"> 105 <\/td>\\n   <td style=\"text-align:right;\"> 6 <\/td>\\n  <\/tr>\\n<\/tbody>\\n<\/table>\r\n\r\nNow, when we feed the table column into the tooltip, we should get a single table for each car on the plot!\r\n\r\n\r\nShow code\r\n\r\ngg_point <- ggplot2::ggplot(data = df) +\r\n  ggiraph::geom_point_interactive(aes(\r\n    x = wt,\r\n    y = qsec,\r\n    color = disp,\r\n    data_id = car,\r\n    tooltip = table\r\n  )) +\r\n  ggplot2::theme_minimal()\r\n\r\nggiraph::girafe(ggobj = gg_point)\r\n\r\n\r\n\r\nCustomizing the tooltip\r\nWe can further customize the appearance of the tooltip tables by using styles from the {kableExtra} package.\r\nIn order to do that, we just need to modify the function we used to create the tables for each car and apply the styles as shown below:\r\n\r\n\r\nShow code\r\n\r\nmake_table <- function(name) {\r\n  data %>%\r\n    # filter by car name\r\n    dplyr::filter(car == name) %>% \r\n    dplyr::select(car, mpg, hp, cyl) %>% \r\n    kableExtra::kbl(row.names = FALSE) %>%\r\n    # change the font family and increase font size\r\n    kableExtra::kable_styling(font_size = 24, html_font = \"Courier New\") %>% \r\n    # increase the width of the columns, make the text blue and bold, apply white background\r\n    kableExtra::column_spec(1:4, width = \"3em\", bold = T, color = \"blue\", background = \"white\")\r\n}\r\n\r\ndf <- data %>% \r\n  dplyr::mutate(table = purrr::map(car, make_table)) %>% \r\n  dplyr::select(car, qsec, wt, disp, table)\r\n\r\n\r\nAnd then call the table within our chart using the same method as before:\r\n\r\n\r\nShow code\r\n\r\ngg_point <- ggplot2::ggplot(data = df) +\r\n  ggiraph::geom_point_interactive(aes(\r\n    x = wt,\r\n    y = qsec,\r\n    color = disp,\r\n    data_id = car,\r\n    tooltip = table\r\n  )) +\r\n  ggplot2::theme_minimal()\r\n\r\nggiraph::girafe(ggobj = gg_point)\r\n\r\n\r\n\r\nUsing {gt} & {gtExtras}\r\nIn addition to the {kableExtra} package, we can also use the {gt} and {gtExtras} packages to build tables for our tooltip.\r\nFor this example, we are going to build a {gt} table that displays the most populous city in each U.S. city (based on the 2010 U.S. Census). The dataset comes from the {usmap} package, which we will also use to build a U.S. map in the next section.\r\nHere is what the full {gt} table looks like with a theme applied from the {gtExtras} package:\r\n\r\n\r\nShow code\r\n\r\nlibrary(gt)\r\nlibrary(gtExtras)\r\nlibrary(usmap)\r\n\r\n# load city population dataset from {usmap}\r\ncities_t <- usmap::usmap_transform(citypop) %>%\r\n    # remove DC from dataset\r\n    dplyr::filter(!state %in% c('District of Columbia')) %>%\r\n    # sort by state\r\n    dplyr::arrange(state)\r\n\r\ngt_table <- cities_t %>% \r\n    dplyr::arrange(state) %>%\r\n    dplyr::select(state, city = most_populous_city, city_pop) %>% \r\n    # create a {gt} table\r\n    gt::gt() %>% \r\n    # add comma delimeters to the city_pop column\r\n    gt::fmt_number(columns = city_pop, decimals = 0) %>%\r\n    # adjust column widths\r\n    gt::cols_width(everything() ~ px(120)) %>%\r\n    # apply the espn theme from {gtExtras}\r\n    gtExtras::gt_theme_espn() %>%\r\n    # add a title and subtitle to the table\r\n    gt::tab_header(title = \"Most Populous City in Each State\", subtitle = \"Source: US Census 2010\") \r\n\r\ngt_table\r\n\r\n\r\nMost Populous City in Each State\r\n    Source: US Census 2010\r\n    state\r\n      city\r\n      city_pop\r\n    Alabama\r\nBirmingham\r\n212,237Alaska\r\nAnchorage\r\n291,826Arizona\r\nPhoenix\r\n1,445,632Arkansas\r\nLittle Rock\r\n193,524California\r\nLos Angeles\r\n3,792,621Colorado\r\nDenver\r\n600,158Connecticut\r\nBridgeport\r\n144,229Delaware\r\nWilmington\r\n70,851Florida\r\nJacksonville\r\n880,619Georgia\r\nAtlanta\r\n420,003Hawaii\r\nHonolulu\r\n337,256Idaho\r\nBoise\r\n205,671Illinois\r\nChicago\r\n2,695,598Indiana\r\nIndianapolis\r\n820,445Iowa\r\nDes Moines\r\n215,472Kansas\r\nWichita\r\n382,368Kentucky\r\nLouisville\r\n597,337Louisiana\r\nNew Orleans\r\n343,829Maine\r\nPortland\r\n66,194Maryland\r\nBaltimore\r\n620,961Massachusetts\r\nBoston\r\n617,594Michigan\r\nDetroit\r\n713,777Minnesota\r\nMinneapolis\r\n382,578Mississippi\r\nJackson\r\n173,514Missouri\r\nKansas City\r\n459,787Montana\r\nBillings\r\n104,170Nebraska\r\nOmaha\r\n466,893Nevada\r\nLas Vegas\r\n583,756New Hampshire\r\nManchester\r\n109,565New Jersey\r\nNewark\r\n277,140New Mexico\r\nAlbuquerque\r\n545,852New York\r\nNew York City\r\n8,175,133North Carolina\r\nCharlotte\r\n731,424North Dakota\r\nFargo\r\n105,549Ohio\r\nColumbus\r\n879,170Oklahoma\r\nOklahoma City\r\n579,999Oregon\r\nPortland\r\n583,776Pennsylvania\r\nPhiladelphia\r\n1,526,006Rhode Island\r\nProvidence\r\n178,042South Carolina\r\nCharleston\r\n129,272South Dakota\r\nSioux Falls\r\n153,888Tennessee\r\nNashville\r\n660,388Texas\r\nHouston\r\n2,099,451Utah\r\nSalt Lake City\r\n186,440Vermont\r\nBurlington\r\n42,417Virginia\r\nVirginia Beach\r\n437,994Washington\r\nSeattle\r\n608,660West Virginia\r\nCharleston\r\n51,400Wisconsin\r\nMilwaukee\r\n594,833Wyoming\r\nCheyenne\r\n59,466\r\n\r\nExtracting the HTML content from a {gt} table\r\nAn important thing to note here is that if we were to apply a {gt} table, such as the one above, directly to {ggiraph}, it would not appear in our tooltip. If you remember earlier when we were using the {kableExtra} package, the tooltip column we created for our tables contained the raw HTML of the table. That is because, by default, {kableExtra} gives you the HTML content that was used to create the table. The {gt} package, however, does not do this by default. Thankfully, though, there is a way of extracting the HTML content of the table using the gt::as_raw_html() function. We can do this by simply piping the table we created directly into the gt::as_raw_html() function as shown below:\r\n\r\n\r\nShow code\r\n\r\n# get HTML content from {gt} table\r\ngt_table_html <- gt_table %>%\r\n    gt::as_raw_html() \r\n\r\n\r\nNow that we have the HTML content of our {gt} table, we can follow the same steps as we did above with our {kableExtra} tables to create a table for each row, or state, in the dataset:\r\n\r\n\r\nShow code\r\n\r\nmake_table <- function(name) {\r\n  cities_t %>% \r\n    # filter by state name\r\n    dplyr::filter(state == name) %>%\r\n    dplyr::arrange(state) %>%\r\n    dplyr::select(state, city = most_populous_city, city_pop) %>% \r\n    gt::gt() %>% \r\n    gt::fmt_number(columns = city_pop, decimals = 0) %>%\r\n    gt::cols_width(everything() ~ px(120)) %>%\r\n    gtExtras::gt_theme_espn() %>%\r\n    gt::tab_header(title = \"Most Populous City in Each State\", subtitle = \"Source: US Census 2010\") %>%\r\n    # get HTML content of table\r\n    gt::as_raw_html()\r\n}\r\n\r\ncities_t <- cities_t %>%\r\n  dplyr::mutate(tooltip = purrr::map(state, make_table))\r\n\r\ngg_map <- usmap::plot_usmap(fill = \"white\", alpha = 0.25) +\r\n        ggiraph::geom_point_interactive(\r\n          data = cities_t, \r\n          ggplot2::aes(\r\n            x = x,\r\n            y = y,\r\n            size = city_pop,\r\n            tooltip = tooltip,\r\n            data_id = state\r\n          ),\r\n          color = \"purple\",\r\n          alpha = 0.8\r\n        ) +\r\n  scale_size_continuous(range = c(1, 16),\r\n                        label = scales::comma) +\r\n  labs(title = \"Most Populous City in Each State\",\r\n       subtitle = \"Source: US Census 2010\",\r\n       size = \"City Population\") +\r\n  theme(legend.position = \"right\")\r\n\r\nggiraph::girafe(ggobj = gg_map)\r\n\r\n\r\n\r\nUsing conditional formatters from {gtExtras}\r\nLet’s say that we wanted to add a column to our table that shows a horizontal bar chart for each city’s population. We can do so by adding gtExtras::gt_color_rows() to our table as shown below:\r\n\r\n\r\nShow code\r\n\r\ncities_t <- usmap_transform(citypop) %>%\r\n  dplyr::filter(!state %in% c('District of Columbia','Alaska','Hawaii')) %>%\r\n  dplyr::arrange(state)\r\n\r\ngt_table <- cities_t %>% \r\n    dplyr::arrange(state) %>%\r\n    dplyr::select(state, city = most_populous_city, city_pop) %>% \r\n    gt::gt() %>% \r\n    gt::fmt_number(columns = city_pop, decimals = 0) %>%\r\n    # add horizontal bar chart to values based on relative population size\r\n    gtExtras::gt_plt_bar(city_pop, keep_column = TRUE) %>%\r\n    gtExtras::gt_theme_espn() %>%\r\n    gt::tab_header(title = \"Most Populous City in Each State\", subtitle = \"Source: US Census 2010\")\r\n\r\ngt_table\r\n\r\n\r\nMost Populous City in Each State\r\n    Source: US Census 2010\r\n    state\r\n      city\r\n      city_pop\r\n      city_pop\r\n    Alabama\r\nBirmingham\r\n212,237\r\nArizona\r\nPhoenix\r\n1,445,632\r\nArkansas\r\nLittle Rock\r\n193,524\r\nCalifornia\r\nLos Angeles\r\n3,792,621\r\nColorado\r\nDenver\r\n600,158\r\nConnecticut\r\nBridgeport\r\n144,229\r\nDelaware\r\nWilmington\r\n70,851\r\nFlorida\r\nJacksonville\r\n880,619\r\nGeorgia\r\nAtlanta\r\n420,003\r\nIdaho\r\nBoise\r\n205,671\r\nIllinois\r\nChicago\r\n2,695,598\r\nIndiana\r\nIndianapolis\r\n820,445\r\nIowa\r\nDes Moines\r\n215,472\r\nKansas\r\nWichita\r\n382,368\r\nKentucky\r\nLouisville\r\n597,337\r\nLouisiana\r\nNew Orleans\r\n343,829\r\nMaine\r\nPortland\r\n66,194\r\nMaryland\r\nBaltimore\r\n620,961\r\nMassachusetts\r\nBoston\r\n617,594\r\nMichigan\r\nDetroit\r\n713,777\r\nMinnesota\r\nMinneapolis\r\n382,578\r\nMississippi\r\nJackson\r\n173,514\r\nMissouri\r\nKansas City\r\n459,787\r\nMontana\r\nBillings\r\n104,170\r\nNebraska\r\nOmaha\r\n466,893\r\nNevada\r\nLas Vegas\r\n583,756\r\nNew Hampshire\r\nManchester\r\n109,565\r\nNew Jersey\r\nNewark\r\n277,140\r\nNew Mexico\r\nAlbuquerque\r\n545,852\r\nNew York\r\nNew York City\r\n8,175,133\r\nNorth Carolina\r\nCharlotte\r\n731,424\r\nNorth Dakota\r\nFargo\r\n105,549\r\nOhio\r\nColumbus\r\n879,170\r\nOklahoma\r\nOklahoma City\r\n579,999\r\nOregon\r\nPortland\r\n583,776\r\nPennsylvania\r\nPhiladelphia\r\n1,526,006\r\nRhode Island\r\nProvidence\r\n178,042\r\nSouth Carolina\r\nCharleston\r\n129,272\r\nSouth Dakota\r\nSioux Falls\r\n153,888\r\nTennessee\r\nNashville\r\n660,388\r\nTexas\r\nHouston\r\n2,099,451\r\nUtah\r\nSalt Lake City\r\n186,440\r\nVermont\r\nBurlington\r\n42,417\r\nVirginia\r\nVirginia Beach\r\n437,994\r\nWashington\r\nSeattle\r\n608,660\r\nWest Virginia\r\nCharleston\r\n51,400\r\nWisconsin\r\nMilwaukee\r\n594,833\r\nWyoming\r\nCheyenne\r\n59,466\r\n\r\n\r\nAs you can see, the size of each bar is relative to the overall distribution of population sizes within the column. This would be something fun to add to our tooltip, but look what happens when we do using the same method as before:\r\n\r\n\r\nShow code\r\n\r\nmake_table <- function(name) {\r\n  cities_t %>% \r\n    # filter by state name\r\n    dplyr::filter(state == name) %>%\r\n    dplyr::arrange(state) %>%\r\n    dplyr::select(state, city = most_populous_city, city_pop) %>% \r\n    gt::gt() %>% \r\n    gt::fmt_number(columns = city_pop, decimals = 0) %>%\r\n    # add horizontal bar chart to values based on relative population size\r\n    gtExtras::gt_plt_bar(city_pop, keep_column = TRUE) %>%\r\n    gtExtras::gt_theme_espn() %>%\r\n    gt::tab_header(title = \"Most Populous City in Each State\", subtitle = \"Source: US Census 2010\") %>%\r\n    # get HTML content of table\r\n    gt::as_raw_html()\r\n}\r\n\r\ncities_t <- cities_t %>%\r\n  dplyr::mutate(tooltip = purrr::map(state, make_table))\r\n\r\ngg_map <- usmap::plot_usmap(fill = \"white\", alpha = 0.25) +\r\n        ggiraph::geom_point_interactive(\r\n          data = cities_t, \r\n          ggplot2::aes(\r\n            x = x,\r\n            y = y,\r\n            size = city_pop,\r\n            tooltip = tooltip,\r\n            data_id = state\r\n          ),\r\n          color = \"purple\",\r\n          alpha = 0.8\r\n        ) +\r\n  scale_size_continuous(range = c(1, 16),\r\n                        label = scales::comma) +\r\n  labs(title = \"Most Populous City in Each State\",\r\n       subtitle = \"Source: US Census 2010\",\r\n       size = \"City Population\") +\r\n  theme(legend.position = \"right\")\r\n\r\nggiraph::girafe(ggobj = gg_map)\r\n\r\n\r\n\r\nDid you notice in the map above that all of the purple bar charts were exactly the same length regardless of which state you hovered over? That’s because gtExtras::gt_plt_bar() determines the length of each horizontal bar based on how that value compares to other values within the column. But, since we filter each state BEFORE building our {gt} table, gtExtras::gt_plt_bar() only sees one value within the column and assigns it the same length regardless if the value is 1 or 10,000 because it has no other value to compare it with.\r\nYou may be wondering why we didn’t apply our dplyr::filter() after building our {gt} table instead of before, and the reason is simply because we can’t. Once we pass data through a {gt} table, it gets converted to a gt_tbl object and is no longer compatible with dplyr functions. However, through some HTML-parsing trickery outlined in the next section, we can still filter our {gt} table thanks to the extracted HTML content via gt::as_raw_html().\r\nExtracting HTML content from {gt} tables\r\nHTML table basics\r\nBefore diving in to the HTML output from {gt} tables, it may help to understand the basic structure of HTML tables.\r\nBelow is a simple example of a table created with HTML. Every HTML table starts with <table> and ends with <\/table>. Within the table, the names of the columns are defined in table header, or <th> cells which appear as <th>Column Name<\/th>. Each row in the table starts with <tr> and the data values are stored within <td>Value<\/td>.\r\n\r\n\r\nShow code\r\n\r\n\"<table>\r\n  <tr>\r\n    <th>Column 1<\/th>\r\n  <\/tr>\r\n  <tbody>\r\n    <tr>\r\n      <td>Row 1<\/td>\r\n    <\/tr>\r\n    <tr>\r\n      <td>Row 2<\/td>\r\n    <\/tr>\r\n  <\/tbody>\r\n<\/table>\"\r\n\r\n\r\nColumn 1\r\n  Row 1\r\n    Row 2\r\n    There are many additional options within HTML tables, such as a table title (<caption>), a table footer (<tfoot>), and styling elements that contain CSS code.\r\nHowever, it’s not necessary to know all of that, because all we’re looking for are the names of the states within the table. And given the info above, we know the states will be contained within a row (<tr>) followed by a data cell (<td>) containing the state name, such as: <tr><td>California.\r\nExtracting the head of the table\r\nI mentioned that we will be filtering the part of the table that contains the data for each state so that we can capture the correct size of the horizontal bar charts based on the state’s population. However, before we do that, we need to extract the head of table first. Once we have the HTML content for the head of the table, we can append the HTML content for each one of the states to it so that we can have a complete HTML table for each state.\r\nTo get the HTML content for the head of the table, we can convert the output to a character vector and use strsplit() to split the vector at the point when reach <tr><td which marks the start of the rows that contain our state data. When we run this, it splits our table before each row and stores it within a list. Since we have 48 continental states within our dataset plus the header of the table (remember, even the table headers in an HTML table start with <tr>), our list will contain 49 elements in total:\r\n\r\n\r\nShow code\r\n\r\n# the code used to create our dataset and HTML table:\r\ncities_t <- usmap_transform(citypop) %>%\r\n  dplyr::filter(!state %in% c('District of Columbia','Alaska','Hawaii')) %>%\r\n  dplyr::arrange(state)\r\n\r\ngt_table_html <- cities_t %>% \r\n    dplyr::arrange(state) %>%\r\n    dplyr::select(state, city = most_populous_city, city_pop) %>% \r\n    gt::gt() %>% \r\n    gt::fmt_number(columns = city_pop, decimals = 0) %>%\r\n    gtExtras::gt_plt_bar(city_pop, keep_column = TRUE) %>%\r\n    gtExtras::gt_theme_espn() %>%\r\n    gt::tab_header(title = \"Most Populous City in Each State\", subtitle = \"Source: US Census 2010\") %>%\r\n    gt::as_raw_html()\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nlength(strsplit(as.character(gt_table_html), \"<tr><td\")[[1]])\r\n\r\n[1] 49\r\n\r\nSo, based on what we described above, the head of the table will be contained within the first element of our list, while the data for the states will be contained in the other elements.\r\nLet’s store the head of the table as table_head so that we can append the HTML for the states to it later:\r\n\r\n\r\nShow code\r\n\r\ntable_head <- strsplit(as.character(gt_table_html), \"<tr><td\")[[1]][1]\r\ntable_head\r\n\r\n[1] \"<table style=\\\"font-family: Lato, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 3px; border-top-color: #FFFFFF; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3;\\\">\\n  <thead style=\\\"\\\">\\n    <tr>\\n      <td colspan=\\\"4\\\" style=\\\"background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; color: #333333; font-size: 24px; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-width: 0; font-weight: normal;\\\" style>Most Populous City in Each State<\/td>\\n    <\/tr>\\n    <tr>\\n      <td colspan=\\\"4\\\" style=\\\"background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; font-weight: normal;\\\" style>Source: US Census 2010<\/td>\\n    <\/tr>\\n  <\/thead>\\n  <thead style=\\\"border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3;\\\">\\n    <tr>\\n      <th style=\\\"color: #333333; background-color: #FFFFFF; font-size: 80%; font-weight: bolder; text-transform: uppercase; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; text-align: left;\\\" rowspan=\\\"1\\\" colspan=\\\"1\\\" scope=\\\"col\\\">state<\/th>\\n      <th style=\\\"color: #333333; background-color: #FFFFFF; font-size: 80%; font-weight: bolder; text-transform: uppercase; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; text-align: left;\\\" rowspan=\\\"1\\\" colspan=\\\"1\\\" scope=\\\"col\\\">city<\/th>\\n      <th style=\\\"color: #333333; background-color: #FFFFFF; font-size: 80%; font-weight: bolder; text-transform: uppercase; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; text-align: right; font-variant-numeric: tabular-nums;\\\" rowspan=\\\"1\\\" colspan=\\\"1\\\" scope=\\\"col\\\">city_pop<\/th>\\n      <th style=\\\"color: #333333; background-color: #FFFFFF; font-size: 80%; font-weight: bolder; text-transform: uppercase; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; text-align: left;\\\" rowspan=\\\"1\\\" colspan=\\\"1\\\" scope=\\\"col\\\">city_pop<\/th>\\n    <\/tr>\\n  <\/thead>\\n  <tbody style=\\\"border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3;\\\">\\n    \"\r\n\r\n\r\n\r\nShow code\r\n/* CSS code to prevent HTML output from truncating in output */ \r\npre code {\r\n  white-space: pre-wrap;\r\n}\r\n\r\nExtracting the body of the table\r\nThe data for the states are stored within elements 2 through 49. Before creating the table, we sorted the states in alphabetical order, so the first state that appears in our HTML should be Alabama. There’s a lot of style content within the HTML output shown below, but if you look close enough, you should be able to see the state name (Alabama), city (Birmingham), and population (212,237).\r\n\r\n\r\nShow code\r\n\r\nstrsplit(as.character(gt_table_html), \"<tr><td\")[[1]][2]\r\n\r\n[1] \" style=\\\"padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #F6F7F7; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; text-align: left;\\\">Alabama<\/td>\\n<td style=\\\"padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #F6F7F7; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; text-align: left;\\\">Birmingham<\/td>\\n<td style=\\\"padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #F6F7F7; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; text-align: right; font-variant-numeric: tabular-nums;\\\">212,237<\/td>\\n<td style=\\\"padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #F6F7F7; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; text-align: left;\\\"><?xml version='1.0' encoding='UTF-8' ?><svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' width='198.43pt' height='14.17pt' viewBox='0 0 198.43 14.17'><defs>  <style type='text/css'><![CDATA[    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {      fill: none;      stroke: #000000;      stroke-linecap: round;      stroke-linejoin: round;      stroke-miterlimit: 10.00;    }    .svglite text {      white-space: pre;    }  ]]><\/style><\/defs><rect width='100%' height='100%' style='stroke: none; fill: none;'/><defs>  <clipPath id='cpMC4wMHwxOTguNDN8MC4wMHwxNC4xNw=='>    <rect x='0.00' y='0.00' width='198.43' height='14.17' />  <\/clipPath><\/defs><g clip-path='url(#cpMC4wMHwxOTguNDN8MC4wMHwxNC4xNw==)'><rect x='8.78' y='1.77' width='4.47' height='10.63' style='stroke-width: 1.07; stroke: none; stroke-linecap: square; stroke-linejoin: miter; fill: #A020F0;' /><line x1='8.78' y1='14.17' x2='8.78' y2='0.0000000000000018' style='stroke-width: 2.13; stroke-linecap: butt;' /><\/g><\/svg><\/td><\/tr>\\n    \"\r\n\r\nIn order to pull the HTML content for each of the remaining states in our dataset, we will need to create a for loop that will go through each element in our list, extract the HTML content, and append it to the table_head we created in the previous section and store it in a vector called html_tables.\r\nA couple quick things to note are when we use strsplit() to split the HTML on <tr><td, strsplit() actually will remove the <tr><td during the split. So, in order to add it back in, we can just paste it before the split. The other thing is we will need to add <\/tbody><\/table> to the end of the table body to tell the HTML to close the body and table so that the table can be created.\r\n\r\n\r\nShow code\r\n\r\ntable_body <- c()\r\nfor (i in 2:49) {\r\n  table_body[i - 1] <-\r\n    paste0(\"<tr><td\",\r\n           strsplit(as.character(gt_table_html), \"<tr><td\")[[1]][i],\r\n           \"<\/tbody><\/table>\")\r\n  html_tables <- paste0(table_head, table_body)\r\n}\r\n\r\n\r\nAdding the tables to our tooltip\r\nTo use the HTML tables we created for each state, we will need to create a column containing the code for the HTML within our dataset so that we can call it within the tooltip of ggiraph::geom_point_interactive() just as we did in prior sections.\r\nNow, when we hover over each state, you can see that our bar charts are displaying properly!\r\n\r\n\r\nShow code\r\n\r\ncities_t <- cities_t %>%\r\n  dplyr::mutate(tooltip = data.frame(html_tables))\r\n\r\ngg_map <- usmap::plot_usmap(fill = \"white\", alpha = 0.25) +\r\n        ggiraph::geom_point_interactive(\r\n          data = cities_t, \r\n          ggplot2::aes(\r\n            x = x,\r\n            y = y,\r\n            size = city_pop,\r\n            tooltip = tooltip$html_tables,\r\n            data_id = state\r\n          ),\r\n          color = \"purple\",\r\n          alpha = 0.8\r\n        ) +\r\n  scale_size_continuous(range = c(1, 16),\r\n                        label = scales::comma) +\r\n  labs(title = \"Most Populous City in Each State\",\r\n       subtitle = \"Source: US Census 2010\",\r\n       size = \"City Population\") +\r\n  theme(legend.position = \"right\")\r\n\r\nggiraph::girafe(ggobj = gg_map)\r\n\r\n\r\n\r\nAnoter example of using conditional formatters from {gtExtras} in interactive tooltips\r\nNow that we went over step-by-step on how to add conditional formatters from {gtExtras} to our tooltips, I’ll quickly share another example of how we can create an interactive choropleth map with {ggiraph} and match the color of the state on the map, which pertains to the state’s city with the largest population, to the color of the population within our {gt} table.\r\nHere is the same table we created in the previous section but with gtExtras::gt_color_rows() applied to the city_pop column:\r\n\r\n\r\nShow code\r\n\r\ncities_t <- usmap_transform(citypop) %>%\r\n  dplyr::filter(!state %in% c('District of Columbia','Alaska','Hawaii')) %>%\r\n  dplyr::arrange(state)\r\n\r\ngt_table <- cities_t %>% \r\n    dplyr::arrange(state) %>%\r\n    dplyr::select(state, city = most_populous_city, city_pop) %>% \r\n    gt::gt() %>% \r\n    gt::fmt_number(columns = city_pop, decimals = 0) %>%\r\n    gt::cols_width(everything() ~ px(140)) %>% \r\n    gtExtras::gt_color_rows(city_pop, palette = \"ggsci::blue_material\") %>%\r\n    gtExtras::gt_theme_espn() %>%\r\n    gt::tab_header(title = \"Most Populous City in Each State\", subtitle = \"Source: US Census 2010\")\r\n\r\ngt_table\r\n\r\n\r\nMost Populous City in Each State\r\n    Source: US Census 2010\r\n    state\r\n      city\r\n      city_pop\r\n    Alabama\r\nBirmingham\r\n212,237Arizona\r\nPhoenix\r\n1,445,632Arkansas\r\nLittle Rock\r\n193,524California\r\nLos Angeles\r\n3,792,621Colorado\r\nDenver\r\n600,158Connecticut\r\nBridgeport\r\n144,229Delaware\r\nWilmington\r\n70,851Florida\r\nJacksonville\r\n880,619Georgia\r\nAtlanta\r\n420,003Idaho\r\nBoise\r\n205,671Illinois\r\nChicago\r\n2,695,598Indiana\r\nIndianapolis\r\n820,445Iowa\r\nDes Moines\r\n215,472Kansas\r\nWichita\r\n382,368Kentucky\r\nLouisville\r\n597,337Louisiana\r\nNew Orleans\r\n343,829Maine\r\nPortland\r\n66,194Maryland\r\nBaltimore\r\n620,961Massachusetts\r\nBoston\r\n617,594Michigan\r\nDetroit\r\n713,777Minnesota\r\nMinneapolis\r\n382,578Mississippi\r\nJackson\r\n173,514Missouri\r\nKansas City\r\n459,787Montana\r\nBillings\r\n104,170Nebraska\r\nOmaha\r\n466,893Nevada\r\nLas Vegas\r\n583,756New Hampshire\r\nManchester\r\n109,565New Jersey\r\nNewark\r\n277,140New Mexico\r\nAlbuquerque\r\n545,852New York\r\nNew York City\r\n8,175,133North Carolina\r\nCharlotte\r\n731,424North Dakota\r\nFargo\r\n105,549Ohio\r\nColumbus\r\n879,170Oklahoma\r\nOklahoma City\r\n579,999Oregon\r\nPortland\r\n583,776Pennsylvania\r\nPhiladelphia\r\n1,526,006Rhode Island\r\nProvidence\r\n178,042South Carolina\r\nCharleston\r\n129,272South Dakota\r\nSioux Falls\r\n153,888Tennessee\r\nNashville\r\n660,388Texas\r\nHouston\r\n2,099,451Utah\r\nSalt Lake City\r\n186,440Vermont\r\nBurlington\r\n42,417Virginia\r\nVirginia Beach\r\n437,994Washington\r\nSeattle\r\n608,660West Virginia\r\nCharleston\r\n51,400Wisconsin\r\nMilwaukee\r\n594,833Wyoming\r\nCheyenne\r\n59,466\r\n\r\nAnd here is a choropleth map created with {ggplot2} and {ggriaph} without the interactive tooltip activated:\r\n\r\n\r\nShow code\r\n\r\nstates_map <- ggplot2::map_data(\"state\")\r\ncities_t$state <- tolower(cities_t$state)\r\n\r\ngg_map <- ggplot(cities_t, aes(map_id = state)) +\r\n  ggiraph::geom_map_interactive(\r\n    aes(\r\n      fill = city_pop,\r\n      data_id = state\r\n    ),\r\n    color = \"white\",\r\n    map = states_map\r\n  ) +\r\n  expand_limits(x = states_map$long, y = states_map$lat) +\r\n  ggsci::scale_fill_material(\"blue\",\r\n                             label = scales::comma) +\r\n  labs(title = \"Most Populous City in Each State\",\r\n       subtitle = \"Source: US Census 2010\",\r\n       fill = \"City Population\") +\r\n  theme_void()\r\n\r\ngg_map\r\n\r\n\r\n\r\nBy following the same steps in the previous section, we can extract the HTML content from our {gt} table and build our tooltip that contains the same shade of blue for each state that is seen on the map.\r\n\r\n\r\nShow code\r\n\r\n# get HTML content from the {gt} table\r\ngt_table_html <- gt_table %>%\r\n  gt::as_raw_html()\r\n\r\n# extract HTML content in the head of the table\r\ntable_head <- strsplit(as.character(gt_table_html), \"<tr><td\")[[1]][1]\r\n\r\n# extract HTML content from the body of the table for each state\r\ntable_body <- c()\r\nfor (i in 2:49) {\r\n  table_body[i - 1] <-\r\n    paste0(\"<tr><td\",\r\n           strsplit(as.character(gt_table_html), \"<tr><td\")[[1]][i],\r\n           \"<\/tbody><\/table>\")\r\n  html_tables <- paste0(table_head, table_body)\r\n}\r\n\r\n# add the HTML tables to our dataset\r\ncities_t <- cities_t %>%\r\n  dplyr::mutate(tooltip = data.frame(html_tables))\r\n\r\ngg_map <- ggplot(cities_t, aes(map_id = state)) +\r\n  ggiraph::geom_map_interactive(\r\n    aes(\r\n      fill = city_pop,\r\n      data_id = state,\r\n      tooltip = tooltip$html_tables\r\n    ),\r\n    color = \"white\",\r\n    map = states_map\r\n  ) +\r\n  expand_limits(x = states_map$long, y = states_map$lat) +\r\n  ggsci::scale_fill_material(\"blue\",\r\n                             label = scales::comma) +\r\n  labs(title = \"Most Populous City in Each State\",\r\n       subtitle = \"Source: US Census 2010\",\r\n       fill = \"City Population\") +\r\n  theme_void()\r\n\r\nggiraph::girafe(ggobj = gg_map, width_svg = 5, height_svg = 3)\r\n\r\n\r\n\r\nOther table-making packages\r\nIn this tutorial, we’ve gone through how to build {kableExtra}, {gt}/{gtExtras} tables and place them within {ggiraph} tooltips. Because we need the raw HTML of the table output in order for {ggiraph} to use the table as a tooltip, that limits the types of table-building packages we can use. For example, tables built with {reactable}/{reactablefmtr} are not compatible with {ggiraph} because their output is in JSON format. Thankfully, the {kableExtra} and {gt}/{gtExtras} packages are highly flexible and should give you all the customization options you need for your tooltips.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-09-30-interactive-tooltip-tables/img/gas_map_demo.gif",
    "last_modified": "2022-10-01T20:42:35-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-11-introducing-the-reactablefmtr-package/",
    "title": "Introducing the {reactablefmtr} Package",
    "description": "An R package created to make the styling and customization of {reactable} tables easier.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2021-02-19",
    "categories": [
      "data visualization",
      "tutorial",
      "reactable",
      "reactablefmtr"
    ],
    "contents": "\r\nUpdate\r\nThe {reactablefmtr} package has undergone many enhancements since the date of this post. For the latest features and customization options available, please visit the package site {reactablefmtr}.\r\nAbout\r\nThe {reactablefmtr} package simplifies and enhances the styling and formatting of tables built with the {reactable} R package. The {reactablefmtr} package provides many conditional formatters that are highly customizable and easy to use.\r\nConditionally format tables with color scales, color tiles, and data bars. Assign icons from Font Awesome with icon assign and icon sets.\r\nCustom table themes that can easily be applied to any {reactablefmtr} or {reactable} table.\r\nEmbed images directly from the web into your table.\r\nSave tables as static PNG files or as interactive HTML files.\r\nThe {reactablefmtr} package was built using a combination of R, CSS, and HTML in order to allow any level of R user to build highly customizable and stylish tables without having to learn additional programming languages.\r\nFor more examples, check out the vignettes. To stay up to date with the latest upgrades to the development version, be sure to follow the package news.\r\nInstallation\r\nThe {reactablefmtr} package is available from CRAN and can be installed with:\r\n\r\n\r\nShow code\r\n\r\ninstall.packages(\"reactablefmtr\")\r\n\r\n\r\n\r\nOr install the development version of {reactablefmtr} with:\r\n\r\n\r\nShow code\r\n\r\nremotes::install_github(\"kcuilla/reactablefmtr\")\r\n\r\n\r\n\r\nExamples\r\nData Bars\r\nUse data_bars() to assign horizontal bars to each row. There are many ways to customize the look of data_bars(), including the alignment of the bars, the position of the text labels, and the option to add icons and images to the bars. See the tutorial for customization examples.\r\n\r\nColor Scales\r\nUse color_scales() to assign conditional colors to cells based on their relative values. The color of the text in the cells automatically adjusts based on the shade of the cell color, allowing the use of dark-colored palettes (such as viridis::magma shown below).\r\n\r\n\r\nShow code\r\n\r\nlibrary(reactablefmtr)\r\nlibrary(palmerpenguins)\r\nlibrary(dplyr)\r\nlibrary(viridis)\r\n  \r\ndata <- sample_n(penguins, 50) %>% \r\n  filter(!is.na(bill_length_mm)) %>% \r\n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm)\r\n\r\nreactable(\r\n  data,\r\n  columns = list(\r\n    bill_length_mm = colDef(style = color_scales(data, colors = viridis::magma(5))),\r\n    bill_depth_mm = colDef(style = color_scales(data, colors = viridis::magma(5))),\r\n    flipper_length_mm = colDef(style = color_scales(data, colors = viridis::magma(5)))\r\n  )\r\n)\r\n\r\n\r\n\r\n\r\nBy default, colors are conditionally assigned to values within each column, but can also be assigned to row-wise data as shown below. See the tutorial for more examples.\r\n\r\n\r\nShow code\r\n\r\ndimnames <- list(start(nottem)[1]:end(nottem)[1], month.abb)\r\ntemps <- matrix(nottem, ncol = 12, byrow = TRUE, dimnames = dimnames)\r\ntemps <- as_tibble(temps, rownames = \"Year\")\r\n\r\nreactable(\r\n  temps,\r\n  defaultColDef = colDef(\r\n    style = color_scales(temps, span = TRUE, colors = c(\"#1e90ff\", \"#ffffff\", \"#ff3030\")),\r\n    minWidth = 50\r\n  )\r\n)\r\n\r\n\r\n\r\n\r\nA similar formatter to color_scales() is color_tiles(). Numbers can be formatted using any formatter from the {scales} package, just like how they are in {ggplot2}. See the tutorial for customization options.\r\nIcon Sets\r\nUse icon_sets() to conditionally assign icons to values from the Font Awesome library based on their relative values. Any number of icons and/or colors can be applied to values within each column. Customization options such as number formatting and positioning of icons are also available. See the tutorial for more options.\r\n\r\n\r\nShow code\r\n\r\nmtcars[1:10,c(1,2,4)] %>% \r\nreactable(., \r\n          theme = flatly(),\r\n          defaultColDef = colDef(maxWidth = 150),\r\n          columns = list(\r\n            mpg = colDef(cell = icon_sets(., icons = \"gas-pump\", colors = c(\"red\",\"blue\",\"forestgreen\"))),\r\n            cyl = colDef(cell = icon_sets(., icons = \"car-side\", colors = c(\"red\",\"blue\",\"forestgreen\"))),\r\n            hp = colDef(cell = icon_sets(., icons = \"horse-head\", colors = c(\"red\",\"blue\",\"forestgreen\")))\r\n          )\r\n)\r\n\r\n\r\n\r\n\r\nIcon Assign\r\nUse icon_assign() to assign icons to values from the Font Awesome library. Multiple customization options are available, such as bucketing values and the option to show/hide values next to the icons. See the tutorial for more options.\r\n\r\n\r\nShow code\r\n\r\ndata <- MASS::Cars93[1:20, c(\"Make\", \"Cylinders\", \"MPG.city\", \"Price\")]\r\n\r\ndata$Cylinders <- as.numeric(data$Cylinders)\r\n\r\nreactable(\r\n  data,\r\n  defaultColDef = colDef(align = \"left\", maxWidth = 200),\r\n  columns = list(\r\n    Cylinders = colDef(cell = icon_assign(data)),\r\n    MPG.city = colDef(cell = icon_assign(data, icon = \"envira\", fill_color = \"forestgreen\", buckets = 5, show_values = \"right\")),\r\n    Price = colDef(cell = icon_assign(data, icon = \"dollar-sign\", fill_color = \"red\", empty_color = \"white\", buckets = 5, show_values = \"right\", number_fmt = scales::dollar_format(accuracy = 0.1)))\r\n  )\r\n)\r\n\r\n\r\n\r\n\r\nCustom Themes\r\nWithin {reactablefmtr}, there are 24+ custom table themes. The themes include bootstrap themes, themes inspired by news/sports sites such as The New York Times, FiveThirtyEight, and ESPN, as well as other custom themes that can only be found within {reactablefmtr}. The themes can be applied easily to tables by simply referencing the theme name. Additional customization options, such as changing the font size, font color, etc. are also available.\r\n\r\n\r\nShow code\r\n\r\ndata <- MASS::Cars93[1:20, c(\"Model\", \"MPG.city\", \"MPG.highway\")]\r\n        \r\ndata %>%\r\n  reactable(.,\r\n    theme = slate(),\r\n    defaultColDef = colDef(\r\n      cell = data_bars(., fill_color = viridis::mako(5), background = \"transparent\", text_position = \"inside-end\")\r\n  )\r\n)\r\n\r\n\r\n\r\n\r\nAdd a Title, Subtitle, and Source\r\nTitles and subtitles can be easily placed above any {reactablefmtr} or {reactable} table with add_title() and add_subtitle(). Also have the option to include a source below a table with add_source(). Additional customization options such as changing the alignment, font size, font family, font style, and font color are available within each formatter.\r\n\r\n\r\nShow code\r\n\r\nreactable(iris[10:29, ]) %>%\r\n  add_title(\"This is a title\") %>% \r\n  add_subtitle(\"This is a subtitle\") %>% \r\n  add_source(\"This is a source\")\r\n\r\n\r\nThis is a title\r\nThis is a subtitle\r\n\r\nThis is a source\r\n\r\nSave Static or Interactive Tables\r\n{reactablefmtr} or {reactable} tables can be saved directly to a file as a static PNG image or as an interactive HTML file with save_reactable().\r\nSave as a PNG file:\r\n\r\n\r\nShow code\r\n\r\nsave_reactable(table_name, \"table.png\")\r\n\r\n\r\n\r\nSave as an HTML file:\r\n\r\n\r\nShow code\r\n\r\nsave_reactable(table_name, \"table.html\")\r\n\r\n\r\n\r\nIf custom CSS styling is applied to the table within an R Markdown document:\r\n\r\n\r\nShow code\r\n\r\nsave_reactable(\"table_name.Rmd\", \"table.png\")\r\n\r\n\r\n\r\nIf you prefer to use a pipe:\r\n\r\n\r\nShow code\r\n\r\ntable_name %>%\r\nsave_reactable(\"table.png\")\r\n\r\n\r\n\r\nAcknowledgments & Contributions\r\nA huge thank you to Greg Lin for creating the amazing {reactable} package! Without Greg, {reactablefmtr} simply would not exist!\r\nAlso thank you to June Chao for contributing to the span option in color_scales() and color_tiles()!\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-11-introducing-the-reactablefmtr-package/img/reactablefmtr_hex_logo.png",
    "last_modified": "2022-03-31T16:40:37-04:00",
    "input_file": {},
    "preview_width": 432,
    "preview_height": 500
  },
  {
    "path": "posts/2021-03-10-animating-charts-with-gganimate/",
    "title": "Animating Charts with gganimate",
    "description": "How to make your ggplot2 chart come alive.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2021-02-06",
    "categories": [
      "data visualization",
      "tutorial",
      "ggplot2",
      "gganimate",
      "tidytuesdayand"
    ],
    "contents": "\r\nStatic Chart\r\nBelow is a chart I made for #TidyTuesday, a weekly social data project in R.\r\nThe aim for this project was to display the “Datasaurus Dozen”, which is a dataset that contains 13 sets of data that have nearly identical summary statistics (mean of x, mean of y, standard deviation of x, standard deviation of y, and Pearson correlation between x and y), yet appear to be completely different when shown on a scatter plot.\r\nThe great thing about using the {gganimate} package is that you can add it to an existing {ggplot2} chart. So, the first thing I did was create a normal, static chart below:\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\nlibrary(gganimate)\r\nlibrary(showtext)\r\n\r\n### add google fonts for ggplot\r\nfont_add_google(name = \"Neuton\",\r\n                family = \"Neuton\")\r\nfont_add_google(name = \"Lobster\",\r\n                family = \"Lobster\")\r\nshowtext_auto()\r\n\r\n### read in data from tidytuesday repo\r\ndatasaurus <-\r\n  readr::read_csv(\r\n    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-10-13/datasaurus.csv'\r\n  )\r\n\r\n### summarize dataset\r\ndatasaurus_summary <- datasaurus %>%\r\n  group_by(dataset) %>%\r\n  summarize(\r\n    mean_x = mean(x),\r\n    mean_y = mean(y),\r\n    sd_x = sd(x),\r\n    sd_y = sd(y),\r\n    cor = cor(x, y, method = \"pearson\")\r\n  )\r\n\r\ndatasaurus2 <- datasaurus %>%\r\n  inner_join(datasaurus_summary, by = c(\"dataset\" = \"dataset\"))\r\n\r\n### build plot\r\np <- ggplot(datasaurus2, aes(x = x, y = y, color = x)) +\r\n  geom_point(size = 1.5, alpha = 0.8) +\r\n  facet_wrap( ~ dataset, strip.position = \"top\") +\r\n  scale_colour_viridis_c(option = \"plasma\") +\r\n  theme_minimal() +\r\n  theme(\r\n    legend.position = 'none',\r\n    axis.text = element_text(\r\n      color = \"white\",\r\n      family = \"Neuton\",\r\n      size = 11\r\n    ),\r\n    axis.title = element_blank(),\r\n    plot.title = element_text(\r\n      color = \"white\",\r\n      family = \"Lobster\",\r\n      size = 40,\r\n      hjust = 0.5,\r\n      margin = margin(10, 0, 0, 0)\r\n    ),\r\n    plot.subtitle = element_text(\r\n      color = \"white\",\r\n      family = \"Neuton\",\r\n      size = 14,\r\n      hjust = 0.5,\r\n      margin = margin(10, 5, 25, 5)\r\n    ),\r\n    panel.grid.major = element_blank(),\r\n    panel.grid.minor = element_blank(),\r\n    strip.background = element_blank(),\r\n    strip.placement = \"outside\",\r\n    strip.text = element_text(\r\n      color = \"white\",\r\n      family = \"Neuton\",\r\n      size = 12\r\n    ),\r\n    plot.background = element_rect(fill = \"#111111\"),\r\n    plot.margin = unit(c(1, 2, 2, 2), \"lines\")\r\n  ) +\r\n  labs(\r\n    title = \"Stats Only Reveal Part of the Story\",\r\n    subtitle = \"Each of the plots below have nearly identical summary statistics, yet they all look significantly different.\\nThis is why it's important to always visualize your data when analyzing it!\\n\r\n       X Mean: 54.3     |     Y Mean: 47.8     |     X SD: 16.8     |     Y SD: = 26.9     |     Corr.: -0.06\"\r\n  )\r\n\r\n\r\n\r\n\r\nAnimated Chart\r\nThere are different ways that you can animate a chart with {gganimate}. The animation I decided to add was to “reveal” the data points and then make them disappear. To do this, all I needed to do was add transition_reveal() to the end of the static chart made above, along with ease_aes() which controls the progression of the animation.\r\nI decided to “reveal” the data points along the x-axis so that they would appear from left-to-right with transition_reveal(x), but this could be changed to the y-axis to reveal from bottom-to-top, if desired.\r\nNote: the code that begins with animate() is not required to animate the chart. I just used it to save it as a gif for better portability.\r\n\r\n\r\nShow code\r\n\r\n### add animation with gganimate\r\np2 <- p + geom_point(aes(group = seq_along(x))) +\r\n  transition_reveal(x) +\r\n  ease_aes('linear')\r\n\r\n### animate to gif\r\nanimate(\r\n  p2,\r\n  nframes = 40,\r\n  fps = 5,\r\n  end_pause = 5,\r\n  rewind = TRUE,\r\n  width = 900,\r\n  height = 900,\r\n  type = \"cairo\"\r\n)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-10-animating-charts-with-gganimate/img/dino_tidytuesday.gif",
    "last_modified": "2021-06-10T15:39:12-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-10-importing-multiple-files-quickly-and-efficiently/",
    "title": "Importing Multiple Files Quickly and Efficiently",
    "description": "Save countless hours with just one line of code.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2021-01-30",
    "categories": [
      "data wrangling",
      "tutorial",
      "purrr"
    ],
    "contents": "\r\nNeed for Speed\r\n\r\n\r\nIf you’re a data professional like me, odds are that at some point in your career you’ve needed to combine multiple files together.\r\nFor example, let’s say that your boss asks you to analyze the trend of the sales data for your company for the past three months. The sales data are stored in separate .csv files for each month and are named using a “month_year” format.\r\nYou know how to code in R, so rather than copying and pasting everything together in Excel, you run this simple script and save the data for the past three months into a single dataframe called “sales”:\r\n\r\n\r\nShow code\r\n\r\nfile1 <- read.csv(\"october_2020.csv\")\r\nfile2 <- read.csv(\"november_2020.csv\")\r\nfile3 <- read.csv(\"december_2020.csv\")\r\n\r\nfiles <- rbind(file1, file2, file3)\r\n\r\n\r\n\r\nThen you analyze the data and send it over to your boss. Your boss thanks you but tells you that you now need to analyze the sales trend over the past 10 years and it needs to be done ASAP that’s about to start. Suddenly, the method you used above doesn’t seem so efficient anymore now that you have 120 files to combine. Not only is it going to take time for you to type out the names of each file, but there’s also a decent chance that you make a typo, especially given that you’re crunched for time.\r\nThere has to be a faster and easier way of doing this, right?\r\nFast Functions\r\nIf you follow me on Twitter, you may already know the answer to that question is yes!\r\nHere is what Jared Lander, an adjunct professor at Columbia University, said about my proposed solution in the “How it’s going” image on the right:\r\n\r\n\r\n\r\nI have saved clients hundreds of hours with this one line. https://t.co/YNl0oCqZXn\r\n\r\n— Jared Lander (@jaredlander) January 2, 2021\r\n\r\n\r\nHere’s the solution I proposed in the picture above on the right so it’s easier to follow along:\r\n\r\n\r\nShow code\r\n\r\nfiles <- \r\n  list.files(pattern = \"*.csv\") %>%\r\n  map_df(~fread(.))\r\n\r\n\r\n\r\nTo explain how this works, the function list.files() simply generates a list of all of the .csv files (as specified by pattern = \"*.csv\") that are located in your current working directory.\r\n Note: depending on where the files are stored on your computer, you may need to change your working directory to the folder that contains the files. Also, if there are no other file types in your folder, then you don’t need the pattern = \"*.csv\" and just use list.files() instead. \r\nThe list of files are then piped into the map_df() function which comes from the purrr package:\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\n\r\nmap_df\r\n\r\n\r\nfunction (.x, .f, ..., .id = NULL) \r\n{\r\n    if (!is_installed(\"dplyr\")) {\r\n        abort(\"`map_df()` requires dplyr\")\r\n    }\r\n    .f <- as_mapper(.f, ...)\r\n    res <- map(.x, .f, ...)\r\n    dplyr::bind_rows(res, .id = .id)\r\n}\r\n<bytecode: 0x0000000020456068>\r\n<environment: namespace:purrr>\r\n\r\nYou can see that map_df essentially takes the list of files and uses bind_rows() to combine them into a single dataframe by passing it through a function (.f) that you provide. In this case, the function that we are using is fread() which comes from the data.table package. fread() is essentially the same as read.csv() but it is significantly faster.\r\n Note: if you want to use any of the arguments within fread() such as stringsAsFactors, select, fill, etc. then you need to include the ~ before calling fread and your argument options. If you don’t need to add any arguments then you can just simply use map_df(fread). \r\nImporting and Combining 500 .csv Files in ~1 sec\r\nTo demonstrate just how fast and easy it is to use map_df() to import and combine files, I created a folder containing 500 .csv files.\r\nThe files, which were generated using Exportify, consist of different playlists found on Spotify. Below is an example of some of the playlists in the folder:\r\n\r\n\r\nShow code\r\n\r\nhead(list.files())\r\n\r\n\r\n[1] \"'90s_pop_rock_essentials.csv\" \"00s_ballads.csv\"             \r\n[3] \"00s_indie_dance_party.csv\"    \"00s_latino.csv\"              \r\n[5] \"00s_rock_anthems.csv\"         \"10s_rock_anthems.csv\"        \r\n\r\nTo confirm there are 500 files in the folder, we can run length(list.files()) to count the total number of files:\r\n\r\n\r\nShow code\r\n\r\nlength(list.files())\r\n\r\n\r\n[1] 500\r\n\r\nNow that we confirmed that all 500 files are present, let’s import and combine them all into one dataset that just consists of the artist, track, and album name of each song:\r\n\r\n\r\nShow code\r\n\r\nlibrary(data.table)\r\n\r\nfiles <-\r\n  list.files() %>%\r\n  map_df(~fread(., select = c(\"Artist Name\", \"Track Name\", \"Album Name\")))\r\n\r\nstr(files)\r\n\r\n\r\nClasses 'data.table' and 'data.frame':  32751 obs. of  3 variables:\r\n $ Artist Name: chr  \"Third Eye Blind\" \"Counting Crows\" \"Spin Doctors\" \"Semisonic\" ...\r\n $ Track Name : chr  \"Semi-Charmed Life\" \"Mr. Jones\" \"Two Princes\" \"Closing Time\" ...\r\n $ Album Name : chr  \"Third Eye Blind\" \"August And Everything After\" \"Pocket Full Of Kryptonite\" \"Feeling Strangely Fine\" ...\r\n - attr(*, \".internal.selfref\")=<externalptr> \r\n\r\nThe output above shows that there are a total of 32,751 rows in our combined dataset (and three columns which we selected).\r\nSo now the question is how long did it take to import and combine 500 .csv files containing over 32k rows in total?\r\n\r\n\r\nShow code\r\n\r\nlibrary(tictoc)\r\n\r\ntic()\r\nfiles <-\r\n  list.files() %>%\r\n  map_df(~fread(., select = c(\"Artist Name\", \"Track Name\", \"Album Name\")))\r\ntoc()\r\n\r\n\r\n0.72 sec elapsed\r\n\r\nThe answer: just over one second!\r\nBonus: Including File Names\r\nCurrently, our file contains the artist, track, and album name for each song as shown below:\r\n\r\n\r\nShow code\r\n\r\nhead(files)\r\n\r\n\r\n        Artist Name        Track Name                   Album Name\r\n1:  Third Eye Blind Semi-Charmed Life              Third Eye Blind\r\n2:   Counting Crows         Mr. Jones  August And Everything After\r\n3:     Spin Doctors       Two Princes    Pocket Full Of Kryptonite\r\n4:        Semisonic      Closing Time       Feeling Strangely Fine\r\n5: Eagle-Eye Cherry      Save Tonight                   Desireless\r\n6:  Matchbox Twenty              Push Yourself or Someone Like You\r\n\r\nIf you would like to add a column that says what playlist each song came from, we can create a function that inserts the file name as a column called ‘Playlist Name’ using mutate:\r\n\r\n\r\nShow code\r\n\r\nfile_names <- function(x) {\r\n  fread(x, select = c(\"Artist Name\", \"Track Name\", \"Album Name\")) %>% \r\n    mutate(\"Playlist Name\" = str_extract(x, '.*(?=\\\\.csv)'))\r\n}\r\n\r\n\r\n\r\nNote: I’m using str_extract above to remove the ‘.csv’ from each of the playlist names since they are present in the file names.\r\nAnd then all we need to do is call that function within map_df() and now we have our dataset with the names of the playlists included:\r\n\r\n\r\nShow code\r\n\r\nfiles_with_names <-\r\n  list.files() %>%\r\n  map_df(file_names)\r\n\r\nhead(files_with_names)\r\n\r\n\r\n        Artist Name        Track Name                   Album Name\r\n1:  Third Eye Blind Semi-Charmed Life              Third Eye Blind\r\n2:   Counting Crows         Mr. Jones  August And Everything After\r\n3:     Spin Doctors       Two Princes    Pocket Full Of Kryptonite\r\n4:        Semisonic      Closing Time       Feeling Strangely Fine\r\n5: Eagle-Eye Cherry      Save Tonight                   Desireless\r\n6:  Matchbox Twenty              Push Yourself or Someone Like You\r\n              Playlist Name\r\n1: '90s_pop_rock_essentials\r\n2: '90s_pop_rock_essentials\r\n3: '90s_pop_rock_essentials\r\n4: '90s_pop_rock_essentials\r\n5: '90s_pop_rock_essentials\r\n6: '90s_pop_rock_essentials\r\n\r\nOther Fast Functions\r\nIn addition to map_df() there are a couple other functions that you can use to import and combine files quickly and efficiently.\r\nThe first one uses rbindlist() from the data.table package:\r\n\r\n\r\nShow code\r\n\r\ntic()\r\nfiles <- \r\n  rbindlist(lapply(list.files(), fread, select = c(\"Artist Name\", \"Track Name\", \"Album Name\")))\r\ntoc()\r\n\r\n\r\n0.64 sec elapsed\r\n\r\nThis is actually just a tick faster than map_df() and only requires one package (data.table) vs two (data.table and purrr) so it is a solid alternative.\r\nThe other function you can use is vroom() from the vroom package. One minor difference between vroom() vs the other two methods is that the results are stored in a tibble vs a dataframe:\r\n\r\n\r\nShow code\r\n\r\nlibrary(vroom)\r\n\r\ntic()\r\nfiles <- \r\n  vroom(list.files(), col_select = c(\"Artist Name\", \"Track Name\", \"Album Name\"))\r\ntoc()\r\n\r\n\r\n1.36 sec elapsed\r\n\r\nFor this example, vroom() is a tiny bit slower than both map_df() and rbindlist() but is still another great alternative.\r\nSpeed Test Summary\r\nHere is a summary of the three functions we’ve used and how each of them performed when importing and combining 500 .csv files using the microbenchmark package:\r\n\r\n\r\nShow code\r\n\r\nlibrary(microbenchmark)\r\n\r\nspeed_test <- microbenchmark::microbenchmark(\r\n  list.files() %>% map_df(~fread(., select = c(\"Artist Name\", \"Track Name\", \"Album Name\"))),\r\n  rbindlist(lapply(list.files(), fread, select = c(\"Artist Name\", \"Track Name\", \"Album Name\"))),\r\n  vroom(list.files(), col_select = c(\"Artist Name\", \"Track Name\", \"Album Name\")),\r\n  times = 10,\r\n  unit = \"s\"\r\n)\r\n\r\nspeed_test\r\n\r\n\r\nUnit: seconds\r\n                                                                                               expr\r\n     list.files() %>% map_df(~fread(., select = c(\"Artist Name\", \"Track Name\",      \"Album Name\")))\r\n rbindlist(lapply(list.files(), fread, select = c(\"Artist Name\",      \"Track Name\", \"Album Name\")))\r\n                vroom(list.files(), col_select = c(\"Artist Name\", \"Track Name\",      \"Album Name\"))\r\n       min        lq      mean    median        uq       max neval\r\n 0.6942158 0.7135742 0.7247162 0.7206925 0.7397134 0.7610076    10\r\n 0.5521009 0.5650346 0.5706224 0.5705313 0.5773364 0.5867329    10\r\n 1.0408613 1.0548972 1.1123975 1.0894975 1.1900331 1.2344037    10\r\n\r\nAs you can see, all three functions we used (map_df(), rbindlist(), and vroom()) are incredibly fast at importing and combining files in R. For our scenario of combining 500 .csv files containing >32k rows in total, rbindlist() was the fastest, followed closely by map_df() and vroom(). However, depending on the number and size of the files you’re combining, the speeds for each method will vary and this may not always be the order in which they finish iterating. The bottom line is that it doesn’t really matter which of the three methods above that you use to import and combine files because they are all incredibly fast. What matters is that if you’re still using read.csv() and rbind() to import and combine your files, hopefully now you’re aware there are much easier, faster, and infallible ways to accomplish this task.\r\n\r\n\r\n\r\n",
    "preview": "https://media.giphy.com/media/26AHLNr8en8J3ovOo/giphy.gif",
    "last_modified": "2021-06-10T15:38:30-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-09-adding-crosstalk-interactivity/",
    "title": "Using Crosstalk to Add User-Interactivity",
    "description": "Linking an interactive plot and table together with the crosstalk package.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2021-01-15",
    "categories": [
      "data visualization",
      "tutorial",
      "reactable",
      "crosstalk"
    ],
    "contents": "\r\nWhat is Crosstalk?\r\nCrosstalk is an R package that is used to implement cross-interactivity between htmlwidgets. Think of it like Shiny, where you can add filter controls to a shared dataset that can update across multiple plots/tables. The nice thing about crosstalk is that it does not have to be used in Shiny. It can be used in your R console or in an HTML R Markdown document like I am using to display this blog post.\r\nProcess\r\nThe table I will be adding crosstalk interactivity to will be the table I submitted for the 2020 RStudio Table Contest (see the blog post about it here).\r\nThe goal is to link the reactable table I created to a plotly chart and provide additional filter options that control both the table and the chart.\r\nThe main inspiration for this came from 538’s NBA Player Ratings.\r\nBelow, I will show you how I created everything from start to finish. Click “show code” to see the code for each step.\r\nStep 1\r\nLoad Libraries and Gather Data\r\nThe data I used comes from the 2019 NFL Standings & Team Stats page on the Pro Football Reference website. I utilized the rvest package to scrape the data from the AFC and NFC Standings table and combined them into a single dataset.\r\nTo get the primary color for each team, I used the nflfastR package and joined it to the dataset.\r\nI then used packages such as dplyr, tidyr, and stringr to clean and tidy the data so that it could be easily used for visualization.\r\nThe packages used to create the data visualization are reactable, htmltools, htmlwidgets, plotly, and of course, crosstalk.\r\nAn important note: in order to use crosstalk, you must create a shared dataset and call that dataset within both plotly and reactable. Otherwise, your dataset will not communicate and filter with eachother. The code to do this is SharedData$new(dataset).\r\n\r\n\r\nShow code\r\n\r\nlibrary(rvest)\r\nlibrary(dplyr)\r\nlibrary(tidyr)\r\nlibrary(stringr)\r\nlibrary(htmltools)\r\nlibrary(htmlwidgets)\r\nlibrary(reactable)\r\nlibrary(plotly)\r\nlibrary(crosstalk)\r\nlibrary(nflfastR)\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nurl <- \"https://www.pro-football-reference.com/years/2019/\"\r\n\r\nAFC_table <- url %>%\r\n  xml2::read_html() %>%\r\n  html_nodes(xpath = '//*[@id=\"AFC\"]') %>%\r\n  html_table()\r\n\r\nAFC_table <- AFC_table[[1]]\r\n\r\nNFC_table <- url %>%\r\n  xml2::read_html() %>%\r\n  html_nodes(xpath = '//*[@id=\"NFC\"]') %>%\r\n  html_table()\r\n\r\nNFC_table <- NFC_table[[1]]\r\n\r\nNFL_table <- rbind(AFC_table, NFC_table)\r\n\r\nteams_colors <- teams_colors_logos %>% \r\n  filter(!team_abbr %in% c(\"LA\", \"OAK\", \"STL\", \"SD\"))\r\n\r\nNFL_table_clean <- NFL_table %>%\r\n  ### Create NFL divisions column\r\n  mutate(Division = ifelse(str_detect(Tm, \"FC\"), Tm, NA)) %>%\r\n  fill(Division, .direction = \"down\") %>%\r\n  ### Create NFL conferences column\r\n  mutate(Conference = ifelse(str_detect(Division, \"NFC\"), \"NFC\", \"AFC\")) %>%\r\n  ### Remove team division names from Tm column\r\n  filter(str_detect(Tm, \"FC\", negate = TRUE)) %>%\r\n  ### Add column to say if team made playoffs based off of pre-existing asterisks\r\n  mutate(Playoffs = ifelse(str_detect(Tm, \"[*+]\"), \"Yes\", \"No\")) %>%\r\n  ### Remove asterisks and plus signs next to team names\r\n  mutate(Tm = gsub(\"[*+]\", \"\", Tm)) %>%\r\n  rename(Record = `W-L%`) %>%\r\n  ### Convert W, L, T into one column named \"Record\"\r\n  unite(Record, W, L, T, sep = \"-\") %>%\r\n  ### Convert W, L, T into one column named \"Record\"\r\n  mutate(\r\n    Team = case_when(\r\n      Tm == \"Oakland Raiders\" ~ \"Las Vegas Raiders\",\r\n      Tm == \"Washington Redskins\" ~ \"Washington Football Team\",\r\n      T ~ Tm\r\n    )\r\n  ) %>%\r\n  ### Join team colors from nflfastR\r\n  inner_join(teams_colors, by = c(\"Team\" = \"team_name\")) %>% \r\n  mutate(Team = word(Tm, -1)) %>% \r\n  mutate(\r\n    Team = case_when(\r\n      Team == \"Redskins\" ~ \"Washington\",\r\n      TRUE ~ Team\r\n    )\r\n  ) %>%\r\n  ### Convert columns containing numbers from character to numeric\r\n  mutate_at(c(\"SRS\", \"OSRS\", \"DSRS\", \"PF\", \"PA\", \"PD\", \"MoV\", \"SoS\"),\r\n            as.numeric) %>%\r\n  ### Bucket SoS column into four groups, add Rank column by SRS\r\n  mutate(SoS_rating = ntile(SoS, 4),\r\n         Rank = rank(-SRS, ties.method = \"last\")) %>%\r\n  mutate(\r\n    SoS_rating = case_when(\r\n      SoS_rating == 1 ~ \"Easy\",\r\n      SoS_rating == 2 ~ \"Moderate\",\r\n      SoS_rating == 3 ~ \"Difficult\",\r\n      SoS_rating == 4 ~ \"Most Difficult\"\r\n    )\r\n  ) %>%\r\n  mutate(SoS_rating = factor(\r\n    SoS_rating,\r\n    levels = c(\"Easy\", \"Moderate\", \"Difficult\", \"Most Difficult\")\r\n  )) %>%\r\n  select(\r\n    Division,\r\n    Conference,\r\n    Rank,\r\n    Team,\r\n    team_color,\r\n    Record,\r\n    Playoffs,\r\n    SoS_rating,\r\n    PF,\r\n    PA,\r\n    MoV,\r\n    OSRS,\r\n    DSRS,\r\n    SRS\r\n  )\r\n\r\nNFL_table_clean_shared <- SharedData$new(NFL_table_clean)\r\n\r\n\r\n\r\nStep 2\r\nBuild the Interactive Plot\r\nI tried to model the design of the interactive plot after the one shown in 538’s NBA Player Ratings. One element I added was adding color to the circles with the primary color of each team.\r\nWhile creating the interactive plot, I frequently referenced this Plotly guide from the makers of the plotly package. I highly recommend checking out this guide if you are interested in learning plotly.\r\n\r\n\r\nShow code\r\n\r\ninteractive_plot <-\r\n  plot_ly(\r\n    NFL_table_clean_shared,\r\n    x = ~ OSRS,\r\n    y = ~ DSRS,\r\n    text = ~paste(Team),\r\n    hoverinfo = \"text\",\r\n    hovertemplate = paste(\r\n      \"<b>%{text}<\/b><br>\",\r\n      \"%{xaxis.title.text}: <b>%{x:+.1f}<\/b><br>\",\r\n      \"%{yaxis.title.text}: <b>%{y:+.1f}<\/b><br>\",\r\n      \"<extra><\/extra>\"\r\n    ),\r\n    marker = list(\r\n      size = ~ PF,\r\n      sizeref = 1,\r\n      sizemode = 'area',\r\n      color = ~ team_color,\r\n      opacity = 0.6,\r\n      line = list(color = \"black\",\r\n                  width = 1)\r\n    ),\r\n    width = 625,\r\n    height = 400\r\n  ) %>%\r\n  ### Top right (+Offense +Defense)\r\n  add_annotations(\r\n    x = 9,\r\n    y = 9.5,\r\n    xref = \"x\",\r\n    yref = \"y\",\r\n    text = \"+ Offense\",\r\n    bgcolor = \"#67a9cf\",\r\n    showarrow = F\r\n  ) %>%\r\n  add_annotations(\r\n    x = 9,\r\n    y = 8,\r\n    xref = \"x\",\r\n    yref = \"y\",\r\n    text = \"+ Defense\",\r\n    bgcolor = \"#67a9cf\",\r\n    showarrow = F\r\n  ) %>%\r\n  ### Bottom left (-Offense -Defense)\r\n  add_annotations(\r\n    x = -8.5,\r\n    y = -8,\r\n    xref = \"x\",\r\n    yref = \"y\",\r\n    text = \"- Offense\",\r\n    bgcolor = \"#fd5e53\",\r\n    showarrow = F\r\n  ) %>%\r\n  add_annotations(\r\n    x = -8.5,\r\n    y = -9.5,\r\n    xref = \"x\",\r\n    yref = \"y\",\r\n    text = \"- Defense\",\r\n    bgcolor = \"#fd5e53\",\r\n    showarrow = F\r\n  ) %>%\r\n  ### Bottom right (+Offense -Defense)\r\n  add_annotations(\r\n    x = 9,\r\n    y = -8,\r\n    xref = \"x\",\r\n    yref = \"y\",\r\n    text = \"+ Offense\",\r\n    bgcolor = \"#67a9cf\",\r\n    showarrow = F\r\n  ) %>%\r\n  add_annotations(\r\n    x = 9,\r\n    y = -9.5,\r\n    xref = \"x\",\r\n    yref = \"y\",\r\n    text = \"- Defense\",\r\n    bgcolor = \"#fd5e53\",\r\n    showarrow = F\r\n  ) %>%\r\n  ### Top left (-Offense +Defense)\r\n  add_annotations(\r\n    x = -8.5,\r\n    y = 9.5,\r\n    xref = \"x\",\r\n    yref = \"y\",\r\n    text = \"- Offense\",\r\n    bgcolor = \"#fd5e53\",\r\n    showarrow = F\r\n  ) %>%\r\n  add_annotations(\r\n    x = -8.5,\r\n    y = 8,\r\n    xref = \"x\",\r\n    yref = \"y\",\r\n    text = \"+ Defense\",\r\n    bgcolor = \"#67a9cf\",\r\n    showarrow = F\r\n  ) %>%\r\n  layout(\r\n    autosize = FALSE,\r\n    xaxis = list(\r\n      range = c(-10.5, 12.5),\r\n      fixedrange = TRUE,\r\n      zeroline = TRUE,\r\n      ticks = \"outside\",\r\n      tickcolor = \"#fff\",\r\n      tickformat = \"+\",\r\n      tickfont = list(size = 14),\r\n      titlefont = list(family = \"Open Sans\",\r\n                       size = 20),\r\n      title = \"Offensive SRS\"\r\n    ),\r\n    yaxis = list(\r\n      range = c(-10.5, 10.5),\r\n      fixedrange = TRUE,\r\n      zeroline = TRUE,\r\n      ticks = \"outside\",\r\n      tickcolor = \"#fff\",\r\n      tickformat = \"+\",\r\n      tickfont = list(size = 14),\r\n      titlefont = list(family = \"Open Sans\",\r\n                       size = 20),\r\n      title = \"Defensive SRS\"\r\n    ),\r\n    hoverlabel = list(font = list(family = \"Open Sans\",\r\n                                  size = 16))\r\n  ) %>%\r\n  highlight(on = \"plotly_selected\") %>%\r\n  config(displayModeBar = FALSE)\r\n\r\n\r\n\r\nStep 3\r\nBuild the Interactive Table\r\nIf you expand the code below, you’ll see that the code to build a table in reactable is quite extensive. I will not go into the details in this post, but do recommend a couple great tutorials that I used to create the interactive table such as this tutorial from Greg Lin, and this from Tom Mock which really helped me understand how to use CSS and Google fonts to enhance the visual appeal of the table (see the “Additional CSS Used for Table” section below for more info).\r\nUpdate: I created a package called reactablefmtr that was designed to make creating tables in reactable MUCH easier. The link to the package site can be found here.\r\n\r\n\r\nShow code\r\n\r\n### format for horizontal bar chart used in the points scored/against columns\r\nbar_chart <-\r\n  function(label,\r\n           width = \"100%\",\r\n           height = \"13px\",\r\n           fill = \"#00bfc4\",\r\n           background = NULL) {\r\n    bar <-\r\n      div(style = list(\r\n        background = fill,\r\n        width = width,\r\n        height = height\r\n      ))\r\n    chart <-\r\n      div(style = list(\r\n        flexGrow = 1,\r\n        marginLeft = \"8px\",\r\n        background = background\r\n      ),\r\n      bar)\r\n    div(style = list(display = \"flex\", alignItems = \"center\"), label, chart)\r\n  }\r\n\r\n### Create orange-blue color palette for Team Rating SRS columns\r\nmake_color_pal <- function(colors, bias = 1) {\r\n  get_color <- colorRamp(colors, bias = bias)\r\n  function(x)\r\n    rgb(get_color(x), maxColorValue = 255)\r\n}\r\noff_rating_color <-\r\n  make_color_pal(c(\"#67a9cf\", \"#f8fcf8\", \"#ef8a62\"), bias = 1.3)\r\ndef_rating_color <-\r\n  make_color_pal(c(\"#67a9cf\", \"#f8fcf8\", \"#ef8a62\"), bias = 0.8)\r\nteam_rating_column <- function(maxWidth = 55, ...) {\r\n  colDef(\r\n    maxWidth = maxWidth,\r\n    align = \"right\",\r\n    class = \"cell number\",\r\n    headerStyle = list(fontWeight = \"500\"),\r\n    ...\r\n  )\r\n}\r\n\r\ntable <-\r\n    reactable(\r\n      NFL_table_clean_shared,\r\n      pagination = FALSE,\r\n      showSortIcon = FALSE,\r\n      highlight = TRUE,\r\n      compact = TRUE,\r\n      defaultSorted = \"SRS\",\r\n      defaultSortOrder = \"desc\",\r\n      defaultColDef = colDef(headerClass = \"header colheader\"),\r\n      columnGroups = list(\r\n        colGroup(\r\n          name = \"Team Rating (SRS)\",\r\n          columns = c(\"SRS\", \"OSRS\", \"DSRS\"),\r\n          headerClass = \"groupheader\"\r\n        ),\r\n        colGroup(\r\n          name = \"Team Scoring & Margin of Victory\",\r\n          columns = c(\"PF\", \"PA\", \"MoV\"),\r\n          headerClass = \"groupheader\"\r\n        )\r\n      ),\r\n      # Add border between Divisions when sorting by Division\r\n      rowClass = JS(\"\r\n        function(rowInfo, state) {\r\n          const firstSorted = state.sorted[0]\r\n          if (firstSorted && firstSorted.id === 'Division') {\r\n            const nextRow = state.pageRows[rowInfo.viewIndex + 1]\r\n            if (nextRow && rowInfo.row.Division !== nextRow.Division) {\r\n              return 'Division-last'\r\n            }\r\n          }\r\n        }\"\r\n      ),\r\n      columns = list(\r\n        Division = colDef(\r\n          class = \"division-name cell\",\r\n          maxWidth = 90,\r\n          ### Group teams into divisions when sorting by division - if sorting by other column then ungroup\r\n          style = JS(\"function(rowInfo, colInfo, state) {\r\n        var firstSorted = state.sorted[0]\r\n        if (!firstSorted || firstSorted.id === 'Division') {\r\n          var prevRow = state.pageRows[rowInfo.viewIndex - 1]\r\n        }\r\n      }\")),\r\n      Team = colDef(\r\n        minWidth = 180,\r\n        class = \"cell\",\r\n        cell = function(value, index) {\r\n          ### Team logos from images folder\r\n          img_src <- knitr::image_uri(sprintf(\"images/%s.png\", value))\r\n          image <- img(class = \"logo\",\r\n                     src = img_src,\r\n                     alt = value)\r\n          div(class = \"team\", image,\r\n            ### Team name\r\n            div(class = \"team-name\", value),\r\n            ### Team record\r\n            div(class = \"record\",  sprintf(\"(%s)\", NFL_table_clean[index, \"Record\"])))\r\n      }\r\n    ), \r\n        ### Hide separate record column\r\n        Record = colDef(show = FALSE),\r\n        team_color = colDef(show = FALSE),\r\n        Rank = colDef(show = FALSE),\r\n        Conference = colDef(show = FALSE),\r\n        SRS = team_rating_column(\r\n          name = \"Total\",\r\n          cell = function(value) {\r\n            ### Normalize team rating in order to assign color from color palette\r\n            normalized <-\r\n              (value - min(NFL_table_clean$SRS)) / (max(NFL_table_clean$SRS) - min(NFL_table_clean$SRS))\r\n            color <- off_rating_color(normalized)\r\n            value <- format(value, nsmall = 1, digits = 1)\r\n            ### Round corners of cell\r\n            div(class = \"roundcorners\",\r\n                style = list(background = color),\r\n                value)\r\n          }\r\n        ),\r\n        OSRS = team_rating_column(\r\n          name = \"Off.\",\r\n          cell = function(value) {\r\n            ### Normalize team rating in order to assign color from color palette\r\n            normalized <-\r\n              (value - min(NFL_table_clean$OSRS)) / (max(NFL_table_clean$OSRS) - min(NFL_table_clean$OSRS))\r\n            color <- off_rating_color(normalized)\r\n            value <- format(value, nsmall = 1, digits = 1)\r\n            ### Round corners of cell\r\n            div(class = \"roundcorners\",\r\n                style = list(background = color),\r\n                value)\r\n          }\r\n        ),\r\n        DSRS = team_rating_column(\r\n          name = \"Def.\",\r\n          cell = function(value) {\r\n          ### Normalize team rating in order to assign color from color palette\r\n            normalized <-\r\n              (value - min(NFL_table_clean$DSRS)) / (max(NFL_table_clean$DSRS) - min(NFL_table_clean$DSRS))\r\n            color <- off_rating_color(normalized)\r\n            value <- format(value, nsmall = 1, digits = 1)\r\n            ### Round corners of cell\r\n            div(class = \"roundcorners\",\r\n                style = list(background = color),\r\n                value)\r\n          }\r\n        ),\r\n        PF = colDef(\r\n          name = \"Pts. Scored\",\r\n          align = \"left\",\r\n          ### Add column border to left side of column\r\n          class = \"border-left cell number\",\r\n          headerStyle = list(fontWeight = \"500\"),\r\n          cell = function(value) {\r\n            ### Calculate width of bar color to display\r\n            width <- paste0(value / max(NFL_table_clean$PF) * 100, \"%\")\r\n            bar_chart(value,\r\n                      width = width,\r\n                      fill = \"#ef8a62\",\r\n                      background = \"#e1e1e1\")\r\n          }\r\n        ),\r\n        PA = colDef(\r\n          name = \"Pts. Against\",\r\n          align = \"left\",\r\n          class = \"cell number\",\r\n          headerStyle = list(fontWeight = \"500\"),\r\n          cell = function(value) {\r\n            ### Calculate width of bar color to display\r\n            width <- paste0(value / max(NFL_table_clean$PA) * 100, \"%\")\r\n            bar_chart(value,\r\n                      width = width,\r\n                      fill = \"#ef8a62\",\r\n                      background = \"#e1e1e1\")\r\n          }\r\n        ),\r\n        MoV = colDef(\r\n          maxWidth = 55,\r\n          ### Add column border to right side of column\r\n          class = \"cell number border-right \",\r\n          headerStyle = list(fontWeight = \"500\"),\r\n          ### For any positive number, add \"+\" sign. For any negative number leave as is\r\n          cell = function(value) {\r\n            if (value > 0)\r\n              paste0(\"+\", value)\r\n            else\r\n              value\r\n          },\r\n          ### For any positive number, assign green color. For any negative number assign red color\r\n          style = function(value) {\r\n            if (value > 0) {\r\n              color <- \"#008000\"\r\n            } else if (value < 0) {\r\n              color <- \"#e00000\"\r\n            } else {\r\n              color <- \"#777\"\r\n            }\r\n            list(color = color)\r\n          }\r\n        ),\r\n        SoS_rating = colDef(\r\n          name = \"SoS\",\r\n          align = \"center\",\r\n          maxWidth = 65,\r\n          class = \"cell number border-left\",\r\n          cell = function(value) {\r\n          ### For teams that were assigned a SoS_rating of 4 (highest rating), show a double-black diamond (note: there was no diamond icon available in the Font Awesome Free library, so the solution was to use a square icon and rotate it at a 45 degree angle)\r\n            if (value == 4) {\r\n              ### In order to display two icons in the same column, they need to be placed in a list\r\n              list(tagAppendAttributes(shiny::icon(\"square\", class = \"rotate\")),\r\n                   tagAppendAttributes(shiny::icon(\"square\", class = \"rotate\")))\r\n              ### For teams that were assigned a SoS_rating of 3, show a single black diamond\r\n            } else if (value == 3) {\r\n              tagAppendAttributes(shiny::icon(\"square\", class = \"rotate\"))\r\n              ### For teams that were assigned a SoS_rating of 2, show a blue square\r\n            } else if (value == 2) {\r\n              tagAppendAttributes(shiny::icon(\"square\"))\r\n            } else {\r\n              ### For teams that were assigned a SoS_rating of 1, show a green circle\r\n              tagAppendAttributes(shiny::icon(\"circle\"))\r\n            }\r\n          },\r\n          style = function(value) {\r\n            ### Assign colors to icons\r\n            if (value %in% c(3, 4)) {\r\n              color <- \"black\"\r\n            } else if (value == 2) {\r\n              color <- \"blue\"\r\n            } else {\r\n              color <- \"green\"\r\n            }\r\n            list(color = color)\r\n          }\r\n        ),\r\n        Playoffs = colDef(\r\n          maxWidth = 75,\r\n          align = \"center\",\r\n          class = \"cell number border-left\",\r\n          ### If team made the playoffs in 2019, assign a green check mark. If they did not, assign a red X symbol\r\n          cell = function(value) {\r\n            if (value == \"Yes\")\r\n              tagAppendAttributes(shiny::icon(\"check\"))\r\n            else\r\n              tagAppendAttributes(shiny::icon(\"times\"))\r\n          },\r\n          ### Assign colors to icons\r\n          style = function(value) {\r\n            if (value == \"Yes\") {\r\n              color <- \"green\"\r\n            } else {\r\n              color <- \"red\"\r\n            }\r\n            list(color = color)\r\n          }\r\n        )\r\n      )\r\n    )\r\n\r\n\r\n\r\nStep 4\r\nAdd Crosstalk Filters\r\nIf you have ever built something in Shiny before, you’ll notice that the crosstalk filters are very similar. You can add a filter to any existing column in the dataset. As you can see in the code below, I used a mixture of filter_checkbox and filter_select depending on how many unique options were available in the column you’re filtering. My rule of thumb is if there are more than five options to choose from it’s probably better to put them into a list in filter_select like I did with the Division filtering as to not take up too much space on the page.\r\n\r\n\r\nShow code\r\n\r\nconf_filter <- filter_checkbox(\r\n  id = \"conf\",\r\n  label = \"Conference\",\r\n  inline = TRUE,\r\n  sharedData = NFL_table_clean_shared,\r\n  group = ~ Conference\r\n)\r\n\r\ndiv_filter <- filter_select(\r\n  id = \"divi\",\r\n  label = \"Division\",\r\n  sharedData = NFL_table_clean_shared,\r\n  group = ~ Division\r\n)\r\n\r\nplayoff_filter <- filter_checkbox(\r\n  id = \"play\",\r\n  label = \"Playoffs\",\r\n  sharedData = NFL_table_clean_shared,\r\n  group = ~ Playoffs\r\n)\r\n\r\nsos_filter <- filter_checkbox(\r\n  id = \"sos\",\r\n  label = \"Strength of Schedule (SoS)\",\r\n  sharedData = NFL_table_clean_shared,\r\n  group = ~ SoS_rating\r\n)\r\n\r\nsrs_filter <- filter_slider(\r\n  id = \"srs\",\r\n  label = \"Team Rating (SRS): Total\",\r\n  sharedData = NFL_table_clean_shared,\r\n  column = ~ SRS,\r\n  ticks = FALSE,\r\n  step = 1\r\n)\r\n\r\n\r\n\r\nStep 5\r\nPut it All Together\r\nFor the layout of the data visualization, I used bscols to place the crosstalk filters side-by-side with the interactive plotly chart.\r\nI then placed the reactable table underneath and added a legend to the table using tags from the htmltools package.\r\nThe final result is shown below. Feel free to click around and the filters and you will notice that both the plot and the table will filter accordingly. Another option is to drag and click on the plot and you will see the table underneath mimic the teams shown.\r\n\r\n\r\nShow code\r\n\r\ndiv(\r\n  div(class = \"title\",\r\n      h2(\"2019 NFL Team Stats & Ratings\")),\r\n  class = \"filtertext\",\r\n  bscols(\r\n    widths = c(3, NA),\r\n    list(\r\n      srs_filter,\r\n      sos_filter,\r\n      conf_filter,\r\n      playoff_filter,\r\n      div_filter\r\n    ),\r\n    interactive_plot\r\n  ),\r\n  div(class = \"linebreak\")\r\n)\r\n\r\n\r\n\r\n\r\n2019 NFL Team Stats & Ratings\r\n\r\n\r\n\r\n\r\n\r\nTeam Rating (SRS): Total\r\n\r\n\r\nStrength of Schedule (SoS)\r\n\r\n\r\n\r\nEasy\r\n\r\n\r\n\r\n\r\nModerate\r\n\r\n\r\n\r\n\r\nDifficult\r\n\r\n\r\n\r\n\r\nMost Difficult\r\n\r\n\r\n\r\n\r\n\r\nConference\r\n\r\n\r\nAFC\r\n\r\n\r\nNFC\r\n\r\n\r\n\r\n\r\nPlayoffs\r\n\r\n\r\n\r\nNo\r\n\r\n\r\n\r\n\r\nYes\r\n\r\n\r\n\r\n\r\n\r\nDivision\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\ndiv(class = \"table-font\",\r\n    table,\r\n  ### Add legend and source below the table\r\n  tags$span(\r\n    style = \"color:#777\",\r\n    \"Note: Strength of Schedule (SoS) aligns with the ski trail difficulty rating system:\", \r\n    ### In order to display icons with color, needed to create a new css class for the symbols that contained a color option\r\n    tagAppendAttributes(shiny::icon(\"circle\", class = \"green-circle-legend\")), \"= Easy\",\r\n    tagAppendAttributes(shiny::icon(\"square\", class = \"blue-square-legend\")), \"= Moderate\",  \r\n    tagAppendAttributes(shiny::icon(\"square\", class = \"black-diamond-legend1\")), \"= Difficult\", \r\n    list(tagAppendAttributes(shiny::icon(\"square\", class = \"black-diamond-legend1\")),\r\n                   tagAppendAttributes(shiny::icon(\"square\", class = \"black-diamond-legend2\"))), \"= Most Difficult\",\r\n    div(\r\n    \"Table created by: Kyle Cuilla @kc_analytics  •  Data: Pro-Football-Reference.com\")\r\n  )\r\n)\r\n\r\n\r\n\r\n\r\n\r\nNote: Strength of Schedule (SoS) aligns with the ski trail difficulty rating system:\r\n\r\n= Easy\r\n\r\n= Moderate\r\n\r\n= Difficult\r\n\r\n\r\n= Most Difficult\r\nTable created by: Kyle Cuilla @kc_analytics  •  Data: Pro-Football-Reference.com\r\n\r\n\r\n\r\nCreated by: @kc_analytics\r\nSource: Pro-Football-Reference\r\nAdditional CSS Used for Table\r\nThis part is optional, but if you want to enhance the aesthetic of your reactable table, one thing you can do is include CSS styling. For example, the column headers in my table were designed to turn grey when you hover and click on them, and that can be seen in the “Column header hover formatting” piece below.\r\n\r\n\r\nShow code\r\n\r\n### Load font from Google Fonts\r\ntags$link(href = \"https://fonts.googleapis.com/css?family=Karla:400,700|Fira+Mono&display=fallback\", rel = \"stylesheet\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n/* Row and column borders */\r\n.cell {\r\n  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.07);\r\n}\r\n.border-left {\r\n  border-left: 1px solid #777;\r\n}\r\n.border-right {\r\n  border-right: 1px solid #777;\r\n}\r\n.Division-last .cell {\r\n  box-shadow: inset 0 -1px 0 #777;\r\n}\r\n/* Column header hover formatting */\r\n.header:hover,\r\n.header[aria-sort=\"ascending\"],\r\n.header[aria-sort=\"descending\"] {\r\n  background-color: #b3b3b3;\r\n  color: #fff;\r\n}\r\n.header:active,\r\n.header[aria-sort=\"ascending\"],\r\n.header[aria-sort=\"descending\"] {\r\n  background-color: #555;\r\n  color: #fff;\r\n}\r\n/* Column header formatting */\r\n.colheader {\r\n  font-family: \"Open Sans\", sans-serif;\r\n  font-size: 15px;\r\n  border-bottom: 2px solid #555;\r\n}\r\n.groupheader {\r\n  font-family: \"Open Sans\", sans-serif;\r\n  font-size: 15px;\r\n}\r\n/* Number formatting */\r\n.number {\r\n  font-family: \"Fira Mono\", Consolas, Monaco, monospace;\r\n  font-size: 13px;\r\n  line-height: 30px;\r\n  white-space: pre;\r\n}\r\n/* Text formatting */\r\n.team-ratings {\r\n  font-family: Karla, \"Helvetica Neue\", Helvetica, Arial, sans-serif;\r\n  font-size: 12px;\r\n}\r\n/* Division column formatting */\r\n.division-name {\r\n  font-family: Karla, \"Helvetica Neue\", Helvetica, Arial, sans-serif;\r\n  font-size: 14px;\r\n  line-height: 30px;\r\n}\r\n/* Team column formatting */\r\n.team {\r\n  display: flex;\r\n  align-items: baseline;\r\n}\r\n.logo {\r\n  margin-right: 10px;\r\n  height: 24px;\r\n}\r\n.team-name {\r\n  font-size: 14px;\r\n  font-weight: 700;\r\n}\r\n.record {\r\n  margin-left: 4px;\r\n  color: #999;\r\n  font-size: 13px;\r\n}\r\n/* Rotate SoS square into a diamond */\r\n.rotate{\r\n  transform: rotate(45deg);\r\n}\r\n/* Round corners under Team Rating columns */\r\n.roundcorners {\r\n  border-radius: 10px;\r\n  color: #000;\r\n  padding-bottom: 2px;\r\n  padding-right: 2px;\r\n  width: 46px;\r\n  height: 28px;\r\n}\r\n/* Formatting for title above table */\r\n.title {\r\n  font-family: \"Open Sans\", sans-serif;\r\n  font-size: 16px;\r\n  margin: 16px 0;\r\n}\r\n/* SoS legend symbols underneath chart */\r\n.black-diamond-legend1{\r\n  transform: rotate(45deg);\r\n  color: #000;\r\n  margin-left: 7px;\r\n}\r\n.black-diamond-legend2{\r\n  transform: rotate(45deg);\r\n  color: #000;\r\n}\r\n.green-circle-legend{\r\n  color: #008000;\r\n  margin-left: 7px;\r\n}\r\n.blue-square-legend{\r\n  color: #0000FF;\r\n  margin-left: 7px;\r\n}\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-09-adding-crosstalk-interactivity/img/crosstalk_gif.gif",
    "last_modified": "2021-06-10T15:40:48-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-05-title-of-post/",
    "title": "2020 RStudio Table Contest",
    "description": "My submission for the 2020 RStudio Table Contest which received an Honorable Mention award.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2021-01-05",
    "categories": [
      "data visualization",
      "reactable"
    ],
    "contents": "\r\nIn late 2020, RStudio announced they were hosting an inaugural table contest. I decided to create a dynamic table that displayed the team ratings and stats from every NFL team from the 2019 season. The data is scraped from Pro Football Reference and the table was created with the reactable package with some CSS styling sprinkled in.\r\nMy submission received an Honorable Mention award from RStudio among 80+ entries.\r\nSee the table below as well as the code for the table located on my GitHub.\r\nNote: if you are viewing on a mobile device, click here to see the full output of the table.\r\n\r\n\r\n\r\n\r\n\r\n\r\n2019 NFL Team Rating & Stats\r\nRatings and results from every NFL team from the 2019 season\r\n\r\n\r\n\r\nNote: Strength of Schedule (SoS) aligns with the ski trail difficulty rating system:\r\n\r\n= Easy\r\n\r\n= Moderate\r\n\r\n= Difficult\r\n\r\n\r\n= Most Difficult\r\nTable created by: Kyle Cuilla @kc_analytics  •  Data: Pro-Football-Reference.com\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-05-title-of-post/img/preview.PNG",
    "last_modified": "2021-06-10T15:22:39-04:00",
    "input_file": {},
    "preview_width": 928,
    "preview_height": 678
  },
  {
    "path": "posts/2021-03-11-the-analytics-say-go-for-it/",
    "title": "The Analytics Say 'Go for It!'",
    "description": "The rate at which NFL teams are going for it on 4th & short are at an all-time high.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2021-01-03",
    "categories": [
      "data visualization",
      "tutorial",
      "reactable",
      "nflfastR"
    ],
    "contents": "\r\nAnalytics are changing the way NFL head coaches make decisions. Teams have been hiring more and more analytics personnel every year over the past few years and leveraging analytics data from third-party companies such as Pro Football Focus. One area that we’ve seen the largest influence from analytics is whether or not teams go for it on 4th down.\r\nTo see this trend, I took a look at the 4th down go-for-it rates since 2010 {nflfastR} package. Excluding plays that were QB kneels, nullified due to penalties, and within a 20-80% estimated win probability, teams went for it on 4th & short (4th & 2 or less) about 26% of the time from 2010-2017. Over the past three years, that number has nearly doubled to 44%. And just in this past year, teams were going for it more often than not (nearly 53%)!\r\nBelow is the code for the analysis and visualization made with {reactable}.\r\nData\r\n\r\n\r\nShow code\r\n\r\nknitr::opts_chunk$set(warning = FALSE, message = FALSE)\r\n\r\n\r\n\r\nThe first step in the analysis is to load the data from {nflfastR}. If you’ve never used {nflfastR} before, they have a great beginner’s guide. This is actually where I got the code for the first part to load data for multiple seasons below:\r\n\r\n\r\nShow code\r\n\r\nlibrary(nflfastR)\r\nlibrary(tidyverse)\r\n\r\nseasons <- 2010:2020\r\n fourth_down_plays <- purrr::map_df(seasons, function(x) {\r\n   readRDS(\r\n     url(\r\n       glue::glue(\"https://raw.githubusercontent.com/guga31bb/nflfastR-data/master/data/play_by_play_{x}.rds\")\r\n     )\r\n   )\r\n }) %>%\r\n   ### filter for 4th down plays only that were not QB kneels\r\n   filter(\r\n     down == 4,\r\n     qb_kneel == 0,\r\n     !is.na(posteam),\r\n     !is.na(yardline_100),\r\n     !is.na(score_differential)\r\n   )\r\n\r\n\r\n\r\nNext step is to calculate go-for-it rates for every team for each season and put in a data table that can be later made into a {reactable} table.\r\nThe {nflfastR} package has an additional table called teams_colors_logos that contains colors for each team which I end up using for the sparklines in my table.\r\n\r\n\r\nShow code\r\n\r\ngo_for_it <- fourth_down_plays %>%\r\n  mutate(\r\n    ### bucket 4th down plays by yards to go\r\n    yards_to_go = case_when(\r\n      ydstogo <= 2 ~ \"2 or less\",\r\n      ydstogo >= 3 & ydstogo <= 5 ~ \"3 to 5\",\r\n      ydstogo >= 6 ~ \"6 or more\",\r\n      TRUE ~ \"NA\"\r\n    )\r\n  ) %>%\r\n  mutate(\r\n    play_type = case_when(\r\n      play_type == \"field_goal\" | play_type == \"punt\" ~ \"Punt/FG\",\r\n      play_type == \"run\" | play_type == \"pass\" ~ \"Run/Pass\",\r\n      play_type == \"no_play\" ~ \"Penalty\",\r\n      TRUE ~ \"NA\"\r\n    )\r\n  ) %>%\r\n  ### exclude penalties and games that were still competitive\r\n  filter(yards_to_go == \"2 or less\" &\r\n           play_type != \"Penalty\" & \r\n           wp > .20 & \r\n           wp < .80) %>%\r\n  dplyr::group_by(season, posteam, play_type) %>%\r\n  summarize(n = n()) %>% \r\n  mutate(`2010-2020` = round(100 * (n / sum(n)), 1)) %>%\r\n  select(-c(n)) %>% \r\n  pivot_wider(names_from = \"season\", values_from = \"2010-2020\") %>%\r\n  filter(play_type == \"Run/Pass\") %>%\r\n  ungroup() %>%\r\n  mutate_if(is.numeric, list(~replace_na(., 0))) %>% \r\n  pivot_longer(cols = starts_with(\"20\"),\r\n               names_to = \"season\",\r\n               values_to = \"2010-2020\") %>% \r\n  arrange(posteam, season)\r\ntrend <- go_for_it %>%\r\n  ungroup() %>%\r\n  select(team = posteam, `2010-2020`) %>%\r\n  group_by(team) %>%\r\n  mutate(`2010-2020` = list(`2010-2020`)) %>%\r\n  distinct(team, `2010-2020`) %>%\r\n  ungroup()\r\ngo_for_it_by_year <- go_for_it %>%\r\n  select(season, team = posteam, `2010-2020`) %>%\r\n  pivot_wider(names_from = \"season\", values_from = \"2010-2020\") %>%\r\n  mutate_if(is.numeric, list(~replace_na(., 0))) %>% \r\n  ungroup() %>%\r\n  inner_join(trend, by = c(\"team\" = \"team\")) %>% \r\n  ### add team colors\r\n  left_join(teams_colors_logos, by = c('team' = 'team_abbr')) %>% \r\n  select(-c(team_name,team_id,team_nick,team_color2,team_color3,team_color4,team_logo_wikipedia,team_logo_espn))\r\n\r\n\r\n\r\nTable\r\nTo visualize the 4th down go-for-it rates, I decided to make an interactive table with {reactable}. The table is sorted by the teams that went for it the most in 2020. As you can see, the Green Bay Packers went for it on 4th and short in game-neutral situations more than any other NFL team at ~82%. This was the second-highest go-for-it rate recorded for a season over the past decade. The highest rate was the Baltimore Ravens who went for it ~90% of the time in 2019. Surprisingly, the Ravens, who are regarded as one of the most analytical teams in the NFL, saw their go-for-it rates fall off in 2020 down to ~50%. Will we continue to see an upwards trend in go-for-it rates across the NFL over the next few seasons, or will teams start to make more conservative decisions like the Ravens did in 2020? Only time will tell…\r\n\r\n\r\nShow code\r\n\r\nlibrary(htmltools)\r\nlibrary(reactable)\r\nlibrary(sparkline)\r\n\r\nmake_color_pal <- function(colors, bias = 1) {\r\n  get_color <- colorRamp(colors, bias = bias)\r\n  function(x)\r\n    rgb(get_color(x), maxColorValue = 255)\r\n}\r\n\r\norange_pal <-\r\n  make_color_pal(c(\r\n    \"#fef4eb\",\r\n    \"#facba6\",\r\n    \"#f8b58b\",\r\n    \"#f59e72\",\r\n    \"#f2855d\",\r\n    \"#ef6a4c\"\r\n  ),\r\n  bias = 0.7)\r\n\r\npct_col <- colDef(\r\n  maxWidth = 60,\r\n  class = \"number\",\r\n  footer = function(value)\r\n    paste0(sprintf(\"%.1f\", mean(value)),\"%\"),\r\n  cell = function(value)\r\n    paste0(format(\r\n      value, digits = 1, nsmall = 1\r\n    ), \"%\"),\r\n  style = function(y) {\r\n    normalized <-\r\n      ((y - 0) / (100 - 0))\r\n    color <- orange_pal(normalized)\r\n    list(background = color)\r\n  }\r\n)\r\n\r\ntable <- reactable(\r\n  go_for_it_by_year,\r\n  pagination = FALSE,\r\n  showSortIcon = FALSE,\r\n  compact = TRUE,\r\n  defaultSorted = \"2020\",\r\n  defaultSortOrder = \"desc\",\r\n  columns = list(\r\n    team = colDef(\r\n      maxWidth = 60,\r\n      align = \"center\",\r\n      footer = \"Avg\",\r\n      cell = function(value, index) {\r\n        ### Team logos from images folder\r\n        img_src <- knitr::image_uri(sprintf(\"images/%s.png\", value))\r\n        image <- img(class = \"logo\",\r\n                     src = img_src,\r\n                     alt = value)\r\n        div(class = \"team\", image)\r\n      }\r\n    ),\r\n    team_color = colDef(show = FALSE),\r\n    `2010` = pct_col,\r\n    `2011` = pct_col,\r\n    `2012` = pct_col,\r\n    `2013` = pct_col,\r\n    `2014` = pct_col,\r\n    `2015` = pct_col,\r\n    `2016` = pct_col,\r\n    `2017` = pct_col,\r\n    `2018` = pct_col,\r\n    `2019` = pct_col,\r\n    `2020` = pct_col,\r\n    `2010-2020` = colDef(\r\n      maxWidth = 130,\r\n      align = \"right\",\r\n      class = \"border-left\",\r\n      cell = function(value, index) {\r\n        sparkline(\r\n          go_for_it_by_year$`2010-2020`[[index]],\r\n          type = \"line\",\r\n          width = 120,\r\n          height = 40,\r\n          lineColor = go_for_it_by_year$team_color[[index]],\r\n          lineWidth = 2,\r\n          fillColor = FALSE,\r\n          spotRadius = 2,\r\n          spotColor = NULL,\r\n          minSpotColor = NULL,\r\n          maxSpotColor = NULL\r\n        )\r\n      }\r\n    )\r\n  ),\r\n  defaultColDef = colDef(\r\n    headerClass = \"header colheader\",\r\n    footerStyle = list(fontWeight = \"bold\", fontSize = \"14px\")\r\n  )\r\n)\r\n### Add title and subtitle to top of page above table\r\ndiv(\r\n  class = \"analytics\",\r\n  div(class = \"title\",\r\n      \"The rate at which NFL teams go for it on 4th & 2-or-less is at an all-time high largely due to the increased use of analytics in decision making.\"),\r\n  table,\r\n  ### Add  source below the table\r\n  tags$span(style = \"color:#999\",\r\n            div(\r\n              \"Note: Percentages shown are how often a team went for it (did not kick a field goal or punt the ball) when it was 4th & 2-or-less and in game-neutral situations (win probability between 20% and 80%). Plays that were nullified due to penalties are not included.\"\r\n            ),\r\n            div(\r\n              \"TABLE: KYLE CUILLA @KC_ANALYTICS  •  DATA: NFLFASTR\"\r\n            ))\r\n)\r\n\r\n\r\n\r\nThe rate at which NFL teams go for it on 4th & 2-or-less is at an all-time high largely due to the increased use of analytics in decision making.\r\n\r\n\r\nNote: Percentages shown are how often a team went for it (did not kick a field goal or punt the ball) when it was 4th & 2-or-less and in game-neutral situations (win probability between 20% and 80%). Plays that were nullified due to penalties are not included.\r\nTABLE: KYLE CUILLA @KC_ANALYTICS  •  DATA: NFLFASTR\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\n### Load font from Google Fonts\r\ntags$link(href = \"https://fonts.googleapis.com/css?family=Karla:400,700|Fira+Mono&display=fallback\", rel = \"stylesheet\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n/* column border */\r\n.border-left {\r\n  border-left: 2px solid #666;\r\n}\r\n/* Column hover formatting */\r\n.header:hover,\r\n.header[aria-sort=\"ascending\"],\r\n.header[aria-sort=\"descending\"] {\r\n  background-color: #dadada;\r\n}\r\n.header:active,\r\n.header[aria-sort=\"ascending\"],\r\n.header[aria-sort=\"descending\"] {\r\n  background-color: #333;\r\n  color: #fff;\r\n}\r\n/* Column header formatting */\r\n.colheader {\r\n  font-family: \"Open Sans\", sans-serif;\r\n  font-size: 12px;\r\n  border-bottom: 2px solid #555;\r\n  text-transform: uppercase;\r\n}\r\n/* Number formatting */\r\n.number {\r\n  font-family: \"Fira Mono\", Consolas, Monaco, monospace;\r\n  font-size: 13px;\r\n  line-height: 34px;\r\n  white-space: pre;\r\n}\r\n/* Text formatting */\r\n.analytics {\r\n  font-family: Karla, \"Helvetica Neue\", Helvetica, Arial, sans-serif;\r\n  font-size: 14px;\r\n}\r\n.logo {\r\n  margin-right: 1px;\r\n  height: 36px;\r\n}\r\n/* Formatting for title above table */\r\n.title {\r\n  font-family: \"Open Sans\", sans-serif;\r\n  font-size: 16px;\r\n  margin: 16px 0;\r\n}\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-11-the-analytics-say-go-for-it/img/go_for_it_table.png",
    "last_modified": "2021-06-10T15:29:26-04:00",
    "input_file": {},
    "preview_width": 859,
    "preview_height": 668
  },
  {
    "path": "posts/2021-03-10-ncaa-tourney-visualization/",
    "title": "NCAA Tourney Visualization",
    "description": "How I created the NCAA Tourney Visualization I made for #TidyTuesday.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2020-10-12",
    "categories": [
      "data visualization",
      "ggplot2",
      "tidytuesday"
    ],
    "contents": "\r\n\r\nData\r\nI created this data visualization as part of the weekly social data project in R called TidyTuesday. Each week, a new dataset is posted, and R users analyze and arrange the data into useful charts using the packages within the tidyverse ecosystem.\r\nThe dataset for this week’s TidyTuesday came from FiveThirtyEight. It contains year-by-year results from each team in the NCAA Women’s Basketball Tournament since 1982. See below for a preview of the raw data:\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\n\r\ntournament <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-10-06/tournament.csv')\r\n\r\nhead(tournament)\r\n\r\n\r\n# A tibble: 6 x 19\r\n   year school  seed conference conf_w conf_l conf_percent conf_place\r\n  <dbl> <chr>  <dbl> <chr>       <dbl>  <dbl>        <dbl> <chr>     \r\n1  1982 Arizo~     4 Western C~     NA     NA         NA   -         \r\n2  1982 Auburn     7 Southeast~     NA     NA         NA   -         \r\n3  1982 Cheyn~     2 Independe~     NA     NA         NA   -         \r\n4  1982 Clems~     5 Atlantic ~      6      3         66.7 4th       \r\n5  1982 Drake      4 Missouri ~     NA     NA         NA   -         \r\n6  1982 East ~     6 Independe~     NA     NA         NA   -         \r\n# ... with 11 more variables: reg_w <dbl>, reg_l <dbl>,\r\n#   reg_percent <dbl>, how_qual <chr>, x1st_game_at_home <chr>,\r\n#   tourney_w <dbl>, tourney_l <dbl>, tourney_finish <chr>,\r\n#   full_w <dbl>, full_l <dbl>, full_percent <dbl>\r\n\r\nThe first thing I was curious about was which teams had been to the most NCAA championship games.\r\n\r\n\r\nShow code\r\n\r\nTOURNAMENT_DATA <- tournament %>%\r\n  mutate(\r\n    tourney_finish = case_when(\r\n      tourney_finish == \"Champ\" ~ \"Champion\",\r\n      tourney_finish == \"N2nd\" ~ \"Runner-up\",\r\n      tourney_finish == \"NSF\" ~ \"Final Four\",\r\n      tourney_finish == \"RF\" ~ \"Elite Eight\",\r\n      tourney_finish == \"RSF\" ~ \"Sweet Sixteen\",\r\n      tourney_finish == \"2nd\" ~ \"2nd Round\",\r\n      tourney_finish == \"1st\" ~ \"1st Round\",\r\n      TRUE ~ \"other\"\r\n    )\r\n  )\r\n\r\nmost_championship_games <- TOURNAMENT_DATA %>%\r\n  group_by(school) %>%\r\n  mutate(\r\n    championship_games = case_when(\r\n      tourney_finish == \"Champion\" | tourney_finish == \"Runner-up\" ~ 1,\r\n      TRUE ~ 0\r\n    )\r\n  ) %>%\r\n  group_by(school) %>%\r\n  summarize(total_championship_games = sum(championship_games)) %>%\r\n  arrange(desc(total_championship_games)) %>%\r\n  top_n(5, total_championship_games)\r\n\r\nmost_championship_games\r\n\r\n\r\n# A tibble: 5 x 2\r\n  school         total_championship_games\r\n  <chr>                             <dbl>\r\n1 Tennessee                            13\r\n2 UConn                                11\r\n3 Louisiana Tech                        6\r\n4 Notre Dame                            6\r\n5 Stanford                              4\r\n\r\nAs you can see, Tennessee has been to the most NCAA championship games since 1982 with 13, followed by UConn with 11.\r\nNext, I wanted to know how often these teams exceeded or under-exceeded their expectations based on their seed heading into the tournament. In order to do this, first I needed to calculate the number of wins expected for each seed in the tournament. I did this by simply taking the average tournament wins for each seed since 1982.\r\n\r\n\r\nShow code\r\n\r\navg_seed_wins <- tournament %>%\r\n  filter(!is.na(seed)) %>%\r\n  group_by(seed) %>%\r\n  summarize(expected_wins = mean(tourney_w)) %>% \r\n  arrange(seed)\r\n\r\navg_seed_wins\r\n\r\n\r\n# A tibble: 16 x 2\r\n    seed expected_wins\r\n   <dbl>         <dbl>\r\n 1     1        3.48  \r\n 2     2        2.48  \r\n 3     3        1.79  \r\n 4     4        1.57  \r\n 5     5        0.993 \r\n 6     6        0.850 \r\n 7     7        0.725 \r\n 8     8        0.518 \r\n 9     9        0.534 \r\n10    10        0.424 \r\n11    11        0.433 \r\n12    12        0.228 \r\n13    13        0.0909\r\n14    14        0     \r\n15    15        0     \r\n16    16        0.0396\r\n\r\nThis shows us that on average, the 1 seed won approximately 3.5 games in the tournament. There are six rounds in the NCAA tournament, so if a team wins six games in a row, they win the championship. Since the 1 seed wins an average of 3.5 games per tournament, they typically reach the Regional Finals or National Semi-finals (also known as the Elite Eight and Final Four). Meanwhile, the 14 and 15 seeds have 0 expected wins, meaning that neither seed has ever won a single game in the tournament.\r\nTo calculate the wins above or below expectations for each of the top 5 teams we selected, I took the number of wins each team won minus the expected wins for their seed. For example, if a team was a 1 seed entering the tournament and ended up winning the championship, this would give them 2.5 wins over expectation since they won 6 games and were only expected to win 3.5 games as a 1 seed.\r\n\r\n\r\nShow code\r\n\r\nexpectations <- TOURNAMENT_DATA %>%\r\n  filter(school %in% most_championship_games$school) %>%\r\n  inner_join(avg_seed_wins, by = c(\"seed\" = \"seed\")) %>%\r\n  group_by(school) %>%\r\n  summarize(\r\n    avg_games_played = mean(tourney_w) + mean(tourney_l),\r\n    avg_actual_wins = mean(tourney_w),\r\n    avg_expected_wins = mean(expected_wins)\r\n  ) %>%\r\n  ungroup() %>%\r\n  mutate(avg_wins_vs_expectations = avg_actual_wins - avg_expected_wins) %>%\r\n  arrange(desc(avg_wins_vs_expectations))\r\n\r\nexpectations\r\n\r\n\r\n# A tibble: 5 x 5\r\n  school avg_games_played avg_actual_wins avg_expected_wi~\r\n  <chr>             <dbl>           <dbl>            <dbl>\r\n1 UConn              4.53            3.9              2.93\r\n2 Notre~             3.4             2.48             1.82\r\n3 Tenne~             4.16            3.38             2.85\r\n4 Stanf~             3.62            2.69             2.37\r\n5 Louis~             3.33            2.41             2.09\r\n# ... with 1 more variable: avg_wins_vs_expectations <dbl>\r\n\r\nBased on this calculation, UConn had the highest average wins over expectation with just under +1, meaning that for every NCAA tournament they participated in, they won 1 more game than they were expected to based on their seed entering the tournament.\r\nVisualization\r\nNow that I had my subdataset, I needed to think of a way to visually display the results. I recently bought a book called Visual Journalism from gestalten that contains data visualizations and infographics from publications from around the world. My inspiration came from a data visualization I saw within that book called, Nobels, no degrees by Giorgia Lupi. The challenge for me was to not only try to adapt a version of this to display basketball data but to also make it in just a matter of a few days in order to be submitted for the current week of TidyTuesday challenge.\r\nThe data visualization I created is not just one chart, but actually multiple charts pieced together. The first chart I made was a line chart showing each team’s wins over expectations for each year they were in the tournament. The solid horizontal line represents the team’s average wins over expectation over the time frame and the dotted line represents the average wins over expectation for the top 5 teams combined. Also, if the red circles around the data points signify if that team won the tournament that year.\r\n\r\nI then created a horizontal bar chart to show the occurrence of each seed the team was when entering the tournament. Each row represents the seeds 1 through 5+ with 1 being on top and 5+ on the bottom:\r\n\r\nAnd last, I created an alluvial chart to show the frequency of tourney finishes for each team. This type of chart does a good job of displaying UConn’s dominance once again as you can see that they ended most of their tournaments as Champions and have never lost a championship game (no lines going to Runner-up).\r\n\r\nPiecing all of the charts together was a bit tedious to get each chart aligned properly so that the data “flowed” through the visualization. I also had to truncate the charts at the top in order to fit the title, description, and legend, but overall I’m happy with the way it turned out. This was my first-ever contribution to the TidyTuesday challenge and I hope to be able to contribute more!\r\n\r\nFull Code\r\n\r\n\r\nShow code\r\n\r\nlibrary(extrafont)\r\nextrafont::loadfonts(device=\"win\")\r\nlibrary(tidyverse)\r\nlibrary(ggtext)\r\nlibrary(ggforce)\r\nlibrary(pdftools)\r\nlibrary(cowplot)\r\n\r\ntournament <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-10-06/tournament.csv')\r\n\r\nTOURNAMENT_DATA <- tournament %>%\r\n  mutate(\r\n    tourney_finish = case_when(\r\n      tourney_finish == \"Champ\" ~ \"Champion\",\r\n      tourney_finish == \"N2nd\" ~ \"Runner-up\",\r\n      tourney_finish == \"NSF\" ~ \"Final Four\",\r\n      tourney_finish == \"RF\" ~ \"Elite Eight\",\r\n      tourney_finish == \"RSF\" ~ \"Sweet Sixteen\",\r\n      tourney_finish == \"2nd\" ~ \"2nd Round\",\r\n      tourney_finish == \"1st\" ~ \"1st Round\",\r\n      TRUE ~ \"other\"\r\n    )\r\n  ) %>%\r\n  mutate(\r\n    school = case_when(\r\n      school == \"Notre Dame\" ~ \"Notre\\nDame\",\r\n      school == \"Louisiana Tech\" ~ \"Louisiana\\nTech\",\r\n      TRUE ~ school\r\n    )\r\n  )\r\n\r\n### top 5 teams in terms of championship game appearances\r\nmost_championship_games <- TOURNAMENT_DATA %>%\r\n  group_by(school) %>%\r\n  mutate(\r\n    championship_games = case_when(\r\n      tourney_finish == \"Champion\" | tourney_finish == \"Runner-up\" ~ 1,\r\n      TRUE ~ 0\r\n    )\r\n  ) %>%\r\n  group_by(school) %>%\r\n  summarize(total_championship_games = sum(championship_games)) %>%\r\n  filter(total_championship_games > 0) %>%\r\n  arrange(desc(total_championship_games)) %>%\r\n  top_n(5, total_championship_games)\r\n\r\navg_seed_wins <- tournament %>%\r\n  filter(!is.na(seed)) %>%\r\n  group_by(seed) %>%\r\n  summarize(expected_wins = mean(tourney_w))\r\n\r\nexpectations <- TOURNAMENT_DATA %>%\r\n  filter(school %in% most_championship_games$school) %>%\r\n  inner_join(avg_seed_wins, by = c(\"seed\" = \"seed\")) %>%\r\n  group_by(school) %>%\r\n  summarize(\r\n    avg_games_played = mean(tourney_w) + mean(tourney_l),\r\n    avg_actual_wins = mean(tourney_w),\r\n    avg_expected_wins = mean(expected_wins)\r\n  ) %>%\r\n  ungroup() %>%\r\n  mutate(avg_wins_vs_expectations = avg_actual_wins - avg_expected_wins) %>%\r\n  arrange(desc(avg_wins_vs_expectations))\r\n\r\ntop_5_avg_expectations <- expectations %>%\r\n  summarize(top_5_avg = mean(avg_wins_vs_expectations))\r\n\r\nteam_expectations <- TOURNAMENT_DATA %>%\r\n  filter(school %in% most_championship_games$school) %>%\r\n  inner_join(avg_seed_wins, by = c(\"seed\" = \"seed\")) %>%\r\n  inner_join(expectations, by = c(\"school\" = \"school\")) %>%\r\n  mutate(wins_vs_expectations = tourney_w - expected_wins)\r\n\r\nteam_expectations$top_5_avg <- top_5_avg_expectations$top_5_avg\r\n\r\n### line chart\r\np <- ggplot(transform(team_expectations,\r\n                      school = factor(\r\n                        school,\r\n                        levels = c(\r\n                          \"UConn\",\r\n                          \"Notre\\nDame\",\r\n                          \"Tennessee\",\r\n                          \"Stanford\",\r\n                          \"Louisiana\\nTech\"\r\n                        )\r\n                      )),\r\n            aes(x = year, y = wins_vs_expectations)) +\r\n  facet_grid(school ~ ., switch = \"y\") +\r\n  geom_hline(\r\n    aes(yintercept = avg_wins_vs_expectations, color = school),\r\n    size = 1.3,\r\n    alpha = 0.8\r\n  ) +\r\n  geom_hline(aes(yintercept = top_5_avg),\r\n             linetype = \"dashed\",\r\n             size = 0.8) +\r\n  geom_line(aes(color = school)) +\r\n  geom_point(size = 4.5, aes(color = school), alpha = 0.6) +\r\n  geom_point(\r\n    pch = 21,\r\n    fill = NA,\r\n    size = 7,\r\n    colour = ifelse(team_expectations$tourney_finish == \"Champion\", \"red\", NA),\r\n    stroke = 1.5\r\n  ) +\r\n  scale_color_manual(\r\n    values = c(\r\n      \"UConn\" = \"#0E1A3E\",\r\n      \"Notre\\nDame\" = \"#217E51\",\r\n      \"Tennessee\" = \"#FF7D00\",\r\n      \"Stanford\" = \"#9A0D20\",\r\n      \"Louisiana\\nTech\" = \"#6FB5EC\"\r\n    )\r\n  ) +\r\n  scale_x_continuous(\r\n    breaks = c(1982, 1990, 2000, 2010, 2018),\r\n    labels = c(\"1982\", \"1990\", \"2000\", \"2010\", \"2018\"),\r\n    position = \"top\",\r\n    expand = (c(-0, 0))\r\n  ) +\r\n  theme_minimal() +\r\n  theme(\r\n    legend.position = \"none\",\r\n    axis.text.x = element_text(size = 17, family = \"Impact\"),\r\n    axis.text.y = element_blank(),\r\n    axis.title = element_blank(),\r\n    strip.text.y.left = element_blank(),\r\n    panel.grid.major.x = element_line(size = 1.1),\r\n    plot.background = element_rect(fill = \"#FFF8E7\", color = \"transparent\")\r\n  ) +\r\n  geom_text(\r\n    x = 1980,\r\n    y = 4,\r\n    aes(label = school, color = school),\r\n    size = 8,\r\n    lineheight = 0.8,\r\n    family = \"Impact\"\r\n  ) +\r\n  geom_text(\r\n    x = 1980,\r\n    aes(\r\n      y = avg_wins_vs_expectations,\r\n      label = round(avg_wins_vs_expectations, 2),\r\n      color = school\r\n    ),\r\n    fontface = \"bold\",\r\n    family = \"Lucida Console\",\r\n    vjust = ifelse(\r\n      team_expectations$avg_wins_vs_expectations > team_expectations$top_5_avg,\r\n      -0.7,\r\n      1.7\r\n    )\r\n  ) +\r\n  geom_text(\r\n    x = 1980,\r\n    aes(y = top_5_avg, label = paste0(\"(\", round(top_5_avg, 2), \")\")),\r\n    color = \"black\",\r\n    fontface = \"bold\",\r\n    family = \"Lucida Console\"\r\n  ) +\r\n  coord_cartesian(clip = \"off\", xlim = c(1982, 2018)) +\r\n  labs(caption = \"Visualization by: Kyle Cuilla . Data by: FiveThirtyEight\") +\r\n  theme(\r\n    plot.margin = unit(c(10, 2.5, 1, 8), \"lines\"),\r\n    plot.caption = element_text(\r\n      hjust = -0.15,\r\n      vjust = -1.5,\r\n      size = 10,\r\n      family = \"Lucida Console\"\r\n    )\r\n  )\r\n\r\n### line chart legends\r\ntourney_expectations_legend <- team_expectations %>%\r\n  filter(school == \"UConn\",\r\n         year >= 1993 & year <= 1997)\r\n\r\np_legend1 <- ggplot(tourney_expectations_legend,\r\n                    aes(x = year, y = wins_vs_expectations)) +\r\n  geom_hline(\r\n    aes(yintercept = avg_wins_vs_expectations, color = school),\r\n    size = 1.3,\r\n    alpha = 0.8\r\n  ) +\r\n  geom_hline(aes(yintercept = top_5_avg),\r\n             linetype = \"dashed\",\r\n             size = 0.8) +\r\n  geom_line(aes(color = school)) +\r\n  geom_point(size = 4.5, aes(color = school), alpha = 0.6) +\r\n  geom_point(\r\n    pch = 21,\r\n    fill = NA,\r\n    size = 7,\r\n    colour = ifelse(\r\n      tourney_expectations_legend$tourney_finish == \"Champion\",\r\n      \"red\",\r\n      NA\r\n    ),\r\n    stroke = 1.5\r\n  ) +\r\n  scale_color_manual(values = c(\"UConn\" = \"#0E1A3E\")) +\r\n  annotate(\r\n    geom = \"text\",\r\n    x = 1996.25,\r\n    y = 2.52,\r\n    label = \"= Won Championship\",\r\n    size = 4.5,\r\n    color = \"red\",\r\n    fontface = \"bold\",\r\n    family = \"Consolas\"\r\n  ) +\r\n  theme_minimal() +\r\n  theme(\r\n    legend.position = \"none\",\r\n    plot.background = element_rect(fill = \"#FFF8E7\", color = \"transparent\"),\r\n    axis.text.y = element_blank(),\r\n    axis.title = element_blank(),\r\n    strip.text.y.left = element_blank()\r\n  ) +\r\n  coord_cartesian(clip = \"off\", xlim = c(1993, 1997)) +\r\n  theme(plot.margin = unit(c(1, 1, 1, 15), \"lines\"),\r\n        axis.text.x = element_blank())\r\n\r\np_legend2 <- ggplot(tourney_expectations_legend,\r\n                    aes(x = year, y = wins_vs_expectations)) +\r\n  geom_hline(\r\n    aes(yintercept = avg_wins_vs_expectations * 1.9, color = school),\r\n    size = 1.3,\r\n    alpha = 0.8\r\n  ) +\r\n  geom_hline(aes(yintercept = top_5_avg / 5),\r\n             linetype = \"dashed\",\r\n             size = 0.8) +\r\n  geom_point(\r\n    pch = 21,\r\n    fill = NA,\r\n    size = 0,\r\n    colour = ifelse(\r\n      tourney_expectations_legend$tourney_finish == \"Champion\",\r\n      \"#FFF8E7\",\r\n      \"#FFF8E7\"\r\n    ),\r\n    stroke = 1.5\r\n  ) +\r\n  scale_color_manual(values = c(\"UConn\" = \"#0E1A3E\")) +\r\n  theme_minimal() +\r\n  theme(\r\n    legend.position = \"none\",\r\n    plot.background = element_rect(fill = \"#FFF8E7\", color = \"transparent\"),\r\n    panel.grid = element_blank(),\r\n    axis.text.y = element_blank(),\r\n    axis.title = element_blank(),\r\n    strip.text.y.left = element_blank()\r\n  ) +\r\n  geom_text(\r\n    x = 1986,\r\n    aes(y = avg_wins_vs_expectations, label = \"Average tourney wins\\n over expectation for each\\n TEAM\", color = school),\r\n    size = 4,\r\n    lineheight = 0.9,\r\n    family = \"Consolas\",\r\n    vjust = -0.3\r\n  ) +\r\n  geom_text(\r\n    x = 1986,\r\n    aes(y = top_5_avg, label = \"Average tourney wins\\n over expectation for the\\n TOP 5 TEAMS\"),\r\n    color = \"black\",\r\n    size = 4,\r\n    lineheight = 0.9,\r\n    family = \"Consolas\",\r\n    vjust = 0.8\r\n  ) +\r\n  coord_cartesian(clip = \"off\", xlim = c(1990, 1995)) +\r\n  theme(plot.margin = unit(c(0, 1, 1, 15), \"lines\"),\r\n        axis.text.x = element_blank()) +\r\n  geom_textbox(\r\n    data = tibble(\r\n      x = 1972,\r\n      y = c(1.2, 0),\r\n      label = c(\r\n        \"<b style='font-size:22pt'>GREAT EXPECTATIONS<\/b><br><br>The top five schools that have been to the most NCAA tournmaent championship games since 1982 and their wins vs expectations.<br><br>\",\r\n        \"<span style='color:#656565'>Note: Expected wins calculated as the average number of wins by seed since 1982.<\/span>\"\r\n      ),\r\n      v = c(0.6, 1.0)\r\n    ),\r\n    aes(\r\n      x = x,\r\n      y = y,\r\n      label = label,\r\n      vjust = v\r\n    ),\r\n    width = unit(3.6, \"inch\"),\r\n    color = \"black\",\r\n    family = \"Consolas\",\r\n    lineheight = 0.95,\r\n    size = 4.2,\r\n    fill = NA,\r\n    box.colour = NA,\r\n    hjust = 0\r\n  ) +\r\n  scale_size_area(max_size = 39 / 4, guide = F)\r\n\r\np_combined <- ggdraw(p) +\r\n  draw_plot(\r\n    p_legend1,\r\n    x = 0.95,\r\n    y = 1,\r\n    width = 0.5,\r\n    height = .15,\r\n    hjust = 1,\r\n    vjust = 1\r\n  ) +\r\n  draw_plot(\r\n    p_legend2,\r\n    x = 0.62,\r\n    y = 1,\r\n    width = 0.35,\r\n    height = .18,\r\n    hjust = 1,\r\n    vjust = 1\r\n  )\r\n\r\ntourney_seed <- TOURNAMENT_DATA %>%\r\n  filter(school %in% most_championship_games$school) %>%\r\n  mutate(seed = case_when(\r\n    seed == 1 ~ \"1\",\r\n    seed == 2 ~ \"2\",\r\n    seed == 3 ~ \"3\",\r\n    seed == 4 ~ \"4\",\r\n    seed >= 5 ~ \"5+\"\r\n  )) %>%\r\n  group_by(school, seed) %>%\r\n  summarize(n = n()) %>%\r\n  ungroup() %>%\r\n  add_row(school = \"Notre\\nDame\",\r\n          seed = \"3\",\r\n          n = 0)\r\n\r\ntourney_results <- TOURNAMENT_DATA %>%\r\n  filter(school %in% most_championship_games$school) %>%\r\n  group_by(school, tourney_finish) %>%\r\n  summarize(n = n()) %>%\r\n  ungroup() %>%\r\n  add_row(school = \"UConn\",\r\n          tourney_finish = \"Runner-up\",\r\n          n = 0) %>%\r\n  add_row(school = \"Louisiana\\nTech\",\r\n          tourney_finish = \"2nd Round\",\r\n          n = 0)\r\n\r\n### horizontal bar chart\r\np2 <- ggplot(transform(\r\n  tourney_seed,\r\n  seed = factor(seed, levels = c(\"5+\", \"4\", \"3\", \"2\", \"1\")),\r\n  school = factor(\r\n    school,\r\n    levels = c(\r\n      \"UConn\",\r\n      \"Notre\\nDame\",\r\n      \"Tennessee\",\r\n      \"Stanford\",\r\n      \"Louisiana\\nTech\"\r\n    )\r\n  )\r\n)) +\r\n  geom_col(aes(x = seed, y = n, fill = school),\r\n           alpha = 0.7,\r\n           width = 0.7) +\r\n  scale_fill_manual(\r\n    values = c(\r\n      \"UConn\" = \"#0E1A3E\",\r\n      \"Notre\\nDame\" = \"#217E51\",\r\n      \"Tennessee\" = \"#FF7D00\",\r\n      \"Stanford\" = \"#9A0D20\",\r\n      \"Louisiana\\nTech\" = \"#6FB5EC\"\r\n    )\r\n  ) +\r\n  coord_flip() +\r\n  facet_grid(school ~ ., switch = \"y\") +\r\n  geom_hline(yintercept = 23, size = 1) +\r\n  geom_segment(aes(\r\n    x = seed,\r\n    y = 0,\r\n    yend = max(n),\r\n    xend = seed\r\n  ), color = \"grey30\") +\r\n  theme(\r\n    legend.position = \"none\",\r\n    plot.background = element_rect(fill = \"#FFF8E7\", color = \"transparent\"),\r\n    panel.background = element_rect(fill = \"#FFF8E7\", color = \"transparent\"),\r\n    panel.grid = element_blank(),\r\n    axis.line.y = element_line(size = 1),\r\n    axis.ticks = element_blank(),\r\n    axis.text = element_blank(),\r\n    axis.title = element_blank(),\r\n    strip.text.y.left = element_blank()\r\n  ) +\r\n  theme(plot.margin = unit(c(12, 0, 2, 0), \"lines\"))\r\n\r\ntourney_seed_legend <- tourney_seed %>%\r\n  filter(school == \"UConn\") %>%\r\n  mutate(n = c(8, 8, 8, 8, 8))\r\n\r\n### horizontal bar chart legend\r\np2_legend <- ggplot(transform(tourney_seed_legend,\r\n                              seed = factor(seed, levels = c(\r\n                                \"5+\", \"4\", \"3\", \"2\", \"1\"\r\n                              )))) +\r\n  coord_flip() +\r\n  facet_grid(school ~ ., switch = \"y\") +\r\n  geom_hline(yintercept = 23, size = 1) +\r\n  geom_segment(aes(\r\n    x = seed,\r\n    y = 0,\r\n    yend = n * 2.87,\r\n    xend = seed\r\n  ), color = \"grey85\") +\r\n  geom_text(\r\n    data = . %>% filter(n == 8),\r\n    aes(label = seed, x = seed, y = n),\r\n    nudge_y = ifelse(tourney_seed_legend$seed == \"5+\", 3.7, 3),\r\n    size = 4.5,\r\n    color = \"black\",\r\n    fontface = \"bold\",\r\n    family = \"Consolas\"\r\n  ) +\r\n  ggtitle(\"Seed\") +\r\n  theme(\r\n    legend.position = \"none\",\r\n    plot.background = element_rect(fill = \"#FFF8E7\", color = \"transparent\"),\r\n    panel.background = element_rect(fill = \"#FFF8E7\", color = \"transparent\"),\r\n    panel.grid = element_blank(),\r\n    text = element_text(family = \"Impact\"),\r\n    axis.line.y = element_line(size = 1),\r\n    axis.ticks = element_blank(),\r\n    axis.text = element_blank(),\r\n    axis.title = element_blank(),\r\n    strip.text.y.left = element_blank(),\r\n    plot.title = element_text(size = 13, hjust = 0.48)\r\n  )  +\r\n  theme(plot.margin = unit(c(1, 0, 0, 0), \"lines\"))\r\n\r\np2 <- ggdraw(p2) +\r\n  draw_plot(\r\n    p2_legend,\r\n    x = 1,\r\n    y = 1,\r\n    width = 1,\r\n    height = .15,\r\n    hjust = 1,\r\n    vjust = 1\r\n  )\r\n\r\n\r\ntourney_results <- TOURNAMENT_DATA %>%\r\n  filter(school %in% most_championship_games$school) %>%\r\n  mutate(seed = case_when(\r\n    seed == 1 ~ \"1\",\r\n    seed == 2 ~ \"2\",\r\n    seed == 3 ~ \"3\",\r\n    seed == 4 ~ \"4\",\r\n    seed >= 5 ~ \"5+\"\r\n  )) %>%\r\n  mutate(\r\n    tourney_finish = case_when(\r\n      tourney_finish == \"Champion\" ~ \"Champion\",\r\n      tourney_finish == \"Runner-up\" ~ \"Runner-up\",\r\n      tourney_finish == \"Final Four\" ~ \"Final Four\",\r\n      tourney_finish == \"Elite Eight\" ~ \"Elite Eight\",\r\n      TRUE ~ \"Sweet Sixteen/earlier\"\r\n    )\r\n  ) %>%\r\n  group_by(school, seed, tourney_finish) %>%\r\n  summarize(n = n()) %>%\r\n  ungroup()\r\n\r\nfct_levels <-\r\n  c(\"UConn\",\r\n    \"Notre\\nDame\",\r\n    \"Tennessee\",\r\n    \"Stanford\",\r\n    \"Louisiana\\nTech\")\r\nfct_levels2 <-\r\n  c(\"Champion\",\r\n    \"Runner-up\",\r\n    \"Final Four\",\r\n    \"Elite Eight\",\r\n    \"Sweet Sixteen/earlier\")\r\n\r\ntourney_results2 <- tourney_results %>%\r\n  select(-c(seed)) %>%\r\n  gather_set_data(1:2) %>%\r\n  mutate_at(vars(school),\r\n            funs(factor(., levels = fct_levels))) %>%\r\n  mutate_at(vars(tourney_finish),\r\n            funs(factor(., levels = fct_levels2)))\r\n\r\n### alluvial chart\r\np3 <-\r\n  ggplot(tourney_results2, aes(\r\n    x = x,\r\n    id = id,\r\n    split = factor(\r\n      y,\r\n      levels = c(\r\n        \"UConn\",\r\n        \"Notre\\nDame\",\r\n        \"Tennessee\",\r\n        \"Stanford\",\r\n        \"Louisiana\\nTech\",\r\n        \"Champion\",\r\n        \"Runner-up\",\r\n        \"Final Four\",\r\n        \"Elite Eight\",\r\n        \"Sweet Sixteen/earlier\"\r\n      )\r\n    ),\r\n    value = n\r\n  )) +\r\n  geom_parallel_sets(\r\n    aes(fill = school),\r\n    alpha = 0.7,\r\n    axis.width = -0.01,\r\n    n = 100,\r\n    strength = 0.5\r\n  ) +\r\n  geom_parallel_sets_axes(fill = \"grey20\", axis.width = -0.01) +\r\n  scale_color_manual(\r\n    values = c(\r\n      \"UConn\" = \"#0E1A3E\",\r\n      \"Notre\\nDame\" = \"#217E51\",\r\n      \"Tennessee\" = \"#FF7D00\",\r\n      \"Stanford\" = \"#9A0D20\",\r\n      \"Louisiana\\nTech\" = \"#6FB5EC\"\r\n    )\r\n  ) +\r\n  scale_fill_manual(\r\n    values = c(\r\n      \"UConn\" = \"#0E1A3E\",\r\n      \"Notre\\nDame\" = \"#217E51\",\r\n      \"Tennessee\" = \"#FF7D00\",\r\n      \"Stanford\" = \"#9A0D20\",\r\n      \"Louisiana\\nTech\" = \"#6FB5EC\"\r\n    )\r\n  ) +\r\n  annotate(\r\n    geom = \"text\",\r\n    x = 2.4,\r\n    y = 170,\r\n    label = \"Champion\",\r\n    size = 6,\r\n    family = \"Impact\"\r\n  ) +\r\n  annotate(\r\n    geom = \"text\",\r\n    x = 2.4,\r\n    y = 142,\r\n    label = \"Runner-up\",\r\n    size = 6,\r\n    family = \"Impact\"\r\n  ) +\r\n  annotate(\r\n    geom = \"text\",\r\n    x = 2.4,\r\n    y = 112,\r\n    label = \"Final Four\",\r\n    size = 6,\r\n    family = \"Impact\"\r\n  ) +\r\n  annotate(\r\n    geom = \"text\",\r\n    x = 2.4,\r\n    y = 75,\r\n    label = \"Elite Eight\",\r\n    size = 6,\r\n    family = \"Impact\"\r\n  ) +\r\n  annotate(\r\n    geom = \"text\",\r\n    x = 2.45,\r\n    y = 25,\r\n    label = \"Sweet Sixteen\\nor earlier\",\r\n    size = 6,\r\n    lineheight = 0.8,\r\n    family = \"Impact\"\r\n  ) +\r\n  theme_minimal() +\r\n  theme(\r\n    legend.position = \"none\",\r\n    plot.background = element_rect(fill = \"#FFF8E7\", color = \"transparent\"),\r\n    panel.grid.major = element_blank(),\r\n    panel.grid.minor = element_blank(),\r\n    axis.text = element_blank(),\r\n    axis.title = element_blank()\r\n  ) +\r\n  coord_cartesian(clip = \"off\") +\r\n  theme(plot.margin = unit(c(10, 3, 0,-6), \"lines\"))\r\n\r\nplot_grid(p_combined,\r\n          p2,\r\n          p3,\r\n          ncol = 3,\r\n          rel_widths = c(4, 0.5, 1))\r\n\r\nggsave(\r\n  \"2020_41_NCAA_Tourney.png\",\r\n  width = 11,\r\n  height = 5,\r\n  device = \"png\",\r\n  type = \"cairo\"\r\n)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-10-ncaa-tourney-visualization/img/tourney_viz.png",
    "last_modified": "2021-06-10T15:35:49-04:00",
    "input_file": {},
    "preview_width": 6000,
    "preview_height": 3000
  },
  {
    "path": "posts/2021-03-10-nfldivisionratings/",
    "title": "Visualizing NFL Division Ratings",
    "description": "Distribution of team ratings by NFL division since 2002.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2020-09-13",
    "categories": [
      "data visualization",
      "data wrangling",
      "tutorial"
    ],
    "contents": "\r\n\r\nProcess\r\nIn my last post, 2019 NFL Team Ratings, I created an interactive visualization to display the NFL team ratings from Pro Football Reference website for the 2019 season.\r\nAfter spending time looking at the 2019 ratings, I was curious to see how each NFL team rated over the past ~20 years and how they compared to other teams within their division.\r\nIn order to do this, I pulled the team ratings for every year since 2002 from Pro Football Reference and plotted the data using the highly versatile ggplot2 package.\r\nThe final plots for each division are located at the end of the article under the Visualization section.\r\nData\r\nThe data I needed to gather was located on 18 different pages from Pro Football Reference’s site (one page for each year from 2002 to 2019). Here is the link for the 2019 team ratings from Pro Football Reference. If you want to view the ratings for any of the prior years, you just need to change the year at the end of the link. In order to pull the data for all 18 years at once, I wrote a function to scrape each year and bind the data together to form one datatset.\r\nI then did some minor cleaning/tidying on the data so that it could be easily used for creating the data visualizations.\r\n\r\n\r\nShow code\r\n\r\nlibrary(rvest)\r\nlibrary(janitor)\r\nlibrary(tidyverse)\r\n\r\n### Pull data from pro-football-reference -----------------------\r\n### AFC tables\r\nget_AFC_tables <- function(year) {\r\n  cat(\"Getting\", year, \"AFC Standings\\n\")\r\n  url <- paste0(\"https://www.pro-football-reference.com/years/\", year)\r\n  AFC <- url %>%\r\n    xml2::read_html() %>%\r\n    html_nodes(xpath = '//*[@id=\"AFC\"]') %>%\r\n    html_table()\r\n  AFC <- AFC[[1]]\r\n  AFC <- AFC %>%\r\n    mutate(Year = year)\r\n}\r\n\r\n### NFC tables\r\nget_NFC_tables <- function(year) {\r\n  cat(\"Getting\", year, \"NFC Standings\\n\")\r\n  url <- paste0(\"https://www.pro-football-reference.com/years/\", year)\r\n  NFC <- url %>%\r\n    xml2::read_html() %>%\r\n    html_nodes(xpath = '//*[@id=\"NFC\"]') %>%\r\n    html_table()\r\n  NFC <- NFC[[1]]\r\n  NFC <- NFC %>%\r\n    mutate(Year = year)\r\n}\r\n\r\nAFC_standings_past18_years <- lapply(2002:2019, get_AFC_tables) %>% \r\n  bind_rows()\r\n\r\nNFC_standings_past18_years <- lapply(2002:2019, get_NFC_tables) %>% \r\n  bind_rows()\r\n\r\n### Clean dataset -----------------------\r\nNFL_table_clean <- AFC_standings_past18_years %>% \r\n  rbind(NFC_standings_past18_years) %>% \r\n  ### Create NFL divisions column\r\n  mutate(Division = ifelse(str_detect(Tm, \"FC\"), Tm, NA)) %>%\r\n  fill(Division, .direction = \"down\") %>%\r\n  ### Create NFL conferences column\r\n  mutate(Conference = ifelse(str_detect(Division, \"NFC\"), \"NFC\", \"AFC\")) %>%\r\n  ### Remove team division names from Tm column\r\n  filter(str_detect(Tm, \"FC\", negate = TRUE)) %>%\r\n  ### Add column to say if team made playoffs based off of pre-existing asterisks\r\n  mutate(Playoffs = ifelse(str_detect(Tm, \"[*+]\"), \"Yes\", \"No\")) %>%\r\n  ### Remove asterisks and plus signs next to team names\r\n  mutate(Tm = gsub(\"[*+]\", \"\", Tm)) %>%\r\n  mutate(\r\n    Team = case_when(\r\n      Tm == \"Oakland Raiders\" ~ \"Las Vegas Raiders\",\r\n      Tm == \"Washington Redskins\" ~ \"Washington Football Team\",\r\n      Tm == \"San Diego Chargers\" ~ \"Los Angeles Chargers\",\r\n      Tm == \"St. Louis Rams\" ~ \"Los Angeles Rams\",\r\n      TRUE ~ Tm\r\n    )\r\n  ) %>%\r\n  ### Convert columns containing numbers from character to numeric\r\n  mutate_at(c(\"SRS\", \"OSRS\", \"DSRS\"),\r\n            as.numeric) %>%\r\n  group_by(Division) %>% \r\n  mutate(\r\n    div_median_SRS = median(SRS)\r\n  ) %>%\r\n  ungroup() %>% \r\n  select(\r\n    Division,\r\n    Conference,\r\n    Team,\r\n    Playoffs,\r\n    OSRS,\r\n    DSRS,\r\n    SRS,\r\n    Year,\r\n    div_median_SRS\r\n  ) %>% \r\n  arrange(SRS)\r\n\r\n\r\n\r\nVisualization\r\n\r\n\r\n\r\n\r\nThe visualizations above shows the distribution of SRS by team and division since 2002 and whether or not the team made the playoffs for each year.\r\nThere are a couple key takeaways that stand out:\r\nThe best division since 2002 in the AFC was the AFC North with a median SRS of +0.7, and the best division in the NFC was the NFC East which also had a median SRS of +0.7\r\nThe New England Patriots have absolutely dominated their division since 2002. Their worst season was still better than the median for their division. They also made the playoffs 89% of the time, the highest in the NFL\r\nIt’s also interesting to see when team’s made the playoffs or not in regards to their SRS rating. For example, the Buffalo Bills and Miami Dolphins did not make the playoffs in their highest rated seasons. Meanwhile, the Denver Broncos made the playoffs in a year in which their SRS rating was -5 (I checked this, and yes, this was the infamous season where Tim Tebow led them to the playoffs in 2011 when they finished the season 8-8)\r\n\r\n\r\nShow code\r\n\r\nlibrary(extrafont)\r\nextrafont::loadfonts(device = \"win\")\r\nlibrary(ggtext)\r\nlibrary(colorspace)\r\nlibrary(nflfastR)\r\n\r\n### Set theme for ggplot -----------------------\r\ntheme_set(theme_minimal(base_size = 18, base_family = \"Lucida Console\"))\r\ntheme_update(\r\n  panel.grid.major = element_line(color = \"grey92\", size = .4),\r\n  panel.grid.minor = element_blank(),\r\n  axis.title.x = element_text(\r\n    size = 15,\r\n    color = \"grey30\",\r\n    margin = margin(t = 7)\r\n  ),\r\n  axis.title.y = element_blank(),\r\n  axis.text = element_text(color = \"grey60\"),\r\n  axis.ticks =  element_line(color = \"grey92\", size = .4),\r\n  axis.ticks.length = unit(.6, \"lines\"),\r\n  legend.position = \"top\",\r\n  plot.title = element_text(\r\n    hjust = 0,\r\n    color = \"black\",\r\n    family = \"Lucida Sans Unicode\",\r\n    size = 21,\r\n    margin = margin(t = 10)\r\n  ),\r\n  plot.subtitle = element_text(\r\n    hjust = 0,\r\n    face = \"bold\",\r\n    color = \"grey30\",\r\n    family = \"Lucida Sans Unicode\",\r\n    size = 16,\r\n    margin = margin(0, 0, 10, 0)\r\n  ),\r\n  plot.title.position = \"plot\",\r\n  plot.caption = element_text(\r\n    color = \"grey50\",\r\n    size = 12,\r\n    hjust = 1,\r\n    family = \"Lucida Sans Unicode\",\r\n    lineheight = 1.05,\r\n    margin = margin(20, 0, 0, 0)\r\n  ),\r\n  plot.caption.position = \"plot\",\r\n  plot.margin = margin(rep(20, 4))\r\n)\r\n\r\n### Create chart for each division -----------------------\r\ndivision <- unique(NFL_table_clean$Division)\r\n\r\nfor (i in division) {\r\ndata <- NFL_table_clean %>% \r\n  filter(Division == i)\r\n\r\ndata <- data %>% \r\n  group_by(Team) %>% \r\n  mutate(\r\n    median = median(SRS),\r\n    q25 = quantile(SRS, probs = .25),\r\n    q75 = quantile(SRS, probs = .75),\r\n    n = n()\r\n  ) %>% \r\n  ungroup() %>% \r\n  mutate(Team_num = as.numeric(fct_rev(Team))) %>% \r\n  arrange(Team)\r\n\r\nteams_colors_logos <- teams_colors_logos %>% \r\n  filter(team_abbr != \"LA\")\r\n\r\nteam_colors <- data %>%\r\n  distinct(Team) %>% \r\n  inner_join(teams_colors_logos, by=c(\"Team\"=\"team_name\")) %>% \r\n  arrange(Team)\r\n\r\npal <- team_colors$team_color\r\n\r\nabbrv <- team_colors$team_abbr\r\n\r\nggplot(data, aes(SRS, Team_num - .2)) +\r\n  geom_linerange(\r\n    data = data %>%\r\n      group_by(Team, Team_num) %>%\r\n      summarize(m = unique(median)) %>% \r\n      ungroup(),\r\n    aes(\r\n      xmin = -Inf,\r\n      xmax = m,\r\n      y = Team_num,\r\n      color = Team\r\n    ),\r\n    inherit.aes = F,\r\n    linetype = \"dotted\",\r\n    size = .5\r\n  ) +\r\n  geom_boxplot(\r\n    aes(\r\n      y = Team_num - .15,\r\n      color = Team,\r\n      color = after_scale(darken(color, .1, space = \"HLS\"))\r\n    ),\r\n    width = 0,\r\n    size = .5,\r\n    outlier.shape = 8\r\n  ) +\r\n  geom_rect(\r\n    aes(\r\n      xmin = q25,\r\n      xmax = median,\r\n      ymin = Team_num - .07,\r\n      ymax = Team_num - .22\r\n    ),\r\n    fill = \"grey95\",\r\n    color = \"grey80\"\r\n  ) +\r\n  geom_rect(\r\n    aes(\r\n      xmin = q75,\r\n      xmax = median,\r\n      ymin = Team_num - .07,\r\n      ymax = Team_num - .22\r\n    ),\r\n    fill = \"grey85\",\r\n    color = \"grey80\"\r\n  ) +\r\n  geom_point(\r\n    aes(y = Team_num - .15),\r\n    color = ifelse(data$Playoffs == \"Yes\", \"darkgreen\", \"red\"),\r\n    shape = 20,\r\n    size = 5,\r\n    alpha = .4\r\n  ) +\r\n  ggdist::stat_halfeye(\r\n    aes(\r\n      y = Team_num,\r\n      color = Team,\r\n      fill = after_scale(lighten(color, .5))\r\n    ),\r\n    alpha = .7,\r\n    shape = 18,\r\n    point_size = 3,\r\n    interval_size = 1.8,\r\n    adjust = .5,\r\n    .width = c(0, 1)\r\n  ) +\r\n  geom_text(\r\n    data = data %>%\r\n      group_by(Team, Team_num) %>%\r\n      summarize(m = unique(median)) %>% \r\n      ungroup(),\r\n    aes(\r\n      x = m,\r\n      y = Team_num + .1,\r\n      label = sprintf(\"%+.1f\", m)\r\n    ),\r\n    inherit.aes = F,\r\n    color = \"white\",\r\n    fontface = \"bold\",\r\n    family = \"Lucida Console\",\r\n    size = 4.5\r\n  ) +\r\n  geom_text(\r\n    data = data %>%\r\n      filter(Team_num == 4) %>%\r\n      summarize(max = max(SRS)) %>% \r\n      ungroup(),\r\n    aes(x = max + 1,\r\n        y = 4 + .05,\r\n        label = \"Playoff Pct.\"),\r\n    inherit.aes = F,\r\n    family = \"Lucida Sans Unicode\",\r\n    color = \"grey20\",\r\n    fontface = \"bold\",\r\n    size = 3.5,\r\n    hjust = 0\r\n  ) +\r\n  geom_text(\r\n    data = data %>%\r\n      mutate(playoff_num = ifelse(Playoffs == \"Yes\", 1, 0)) %>%\r\n      group_by(Team, Team_num) %>%\r\n      summarize(max = max(SRS),\r\n                playoff_pct = round(100 * sum(playoff_num) / 18, 0)) %>% \r\n      ungroup(),\r\n    aes(\r\n      x = max + 1,\r\n      y = Team_num - .15,\r\n      label = glue::glue(\"{playoff_pct}%\"),\r\n      color = Team\r\n    ),\r\n    inherit.aes = F,\r\n    family = \"Lucida Console\",\r\n    fontface = \"bold\",\r\n    size = 4,\r\n    hjust = 0\r\n  ) +\r\n  scale_x_continuous(\r\n    labels = function(x)\r\n      sprintf(\"%+.0f\", x),\r\n    limits = c(-18, 21.5),\r\n    breaks = c(-20, -15, -10, -5, 0, 5, 10, 15, 20)\r\n  ) +\r\n  scale_y_continuous(\r\n    limits = c(.55, NA),\r\n    breaks = 1:4,\r\n    labels = rev(team_colors$team_abbr),\r\n    expand = c(0, 0.05)\r\n  ) +\r\n  scale_color_manual(values = pal,\r\n                     guide = F) +\r\n  scale_fill_manual(values = pal,\r\n                    guide = F) +\r\n  labs(\r\n    x = \"SRS\",\r\n    title = i,\r\n    subtitle = \"Distribution of SRS since 2002\",\r\n    caption = 'Note: Simple Rating System (SRS) is a measurement of team quality relative to average (0.0)\\nVisualization: Kyle Cuilla  •  Data: Pro-Football-Reference'\r\n  ) +\r\n  theme(\r\n    panel.grid.major.y = element_blank(),\r\n    axis.text.y = element_text(\r\n      family = \"Lucida Console\",\r\n      color = rev(pal),\r\n      size = 20,\r\n      lineheight = .9\r\n    ),\r\n    axis.ticks.length = unit(0, \"lines\")\r\n  ) +\r\n  geom_vline(\r\n    xintercept = data$div_median_SRS,\r\n    linetype = \"dashed\",\r\n    size = 0.5,\r\n    alpha = 0.5\r\n  ) +\r\n  geom_text(\r\n    data = data %>%\r\n      filter(Team_num == 4),\r\n    aes(\r\n      x = div_median_SRS + 0.4,\r\n      y = 4 + 1,\r\n      label = paste0(\"Division median: \", sprintf(\"%+.1f\", div_median_SRS))\r\n    ),\r\n    inherit.aes = F,\r\n    family = \"Lucida Sans Unicode\",\r\n    color = \"grey20\",\r\n    fontface = \"bold.italic\",\r\n    size = 3.8,\r\n    hjust = 0\r\n  ) +\r\n  annotate(\r\n    \"text\",\r\n    x = 17.5,\r\n    y = 5,\r\n    label = \"Playoffs\",\r\n    family = \"Lucida Sans Unicode\",\r\n    color = \"grey20\",\r\n    fontface = \"bold\",\r\n    size = 4,\r\n    lineheight = .9\r\n  )  +\r\n  geom_point(\r\n    x = 16.5,\r\n    y = 4.7,\r\n    color = \"darkgreen\",\r\n    shape = 20,\r\n    size = 5,\r\n    alpha = .5\r\n  ) +\r\n  annotate(\r\n    \"text\",\r\n    x = 16.5,\r\n    y = 4.85,\r\n    label = \"Yes\",\r\n    family = \"Lucida Sans Unicode\",\r\n    color = \"grey20\",\r\n    size = 3.2,\r\n    lineheight = .9\r\n  ) +\r\n  geom_point(\r\n    x = 18,\r\n    y = 4.7,\r\n    color = \"red\",\r\n    shape = 20,\r\n    size = 5,\r\n    alpha = .5\r\n  ) +\r\n  annotate(\r\n    \"text\",\r\n    x = 18,\r\n    y = 4.85,\r\n    label = \"No\",\r\n    family = \"Lucida Sans Unicode\",\r\n    color = \"grey20\",\r\n    size = 3.2,\r\n    lineheight = .9\r\n  ) \r\n\r\nggsave(file = paste0(i, \" Division.png\"), height = 4, width = 4, device = \"png\", type = \"cairo\")\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-10-nfldivisionratings/img/AFC North Division.png",
    "last_modified": "2021-06-10T15:32:40-04:00",
    "input_file": {},
    "preview_width": 2400,
    "preview_height": 2400
  },
  {
    "path": "posts/2021-03-09-re-creating-a-chart-from-npr-with-ggplot2/",
    "title": "Re-creating a Chart from NPR with ggplot2",
    "description": "Step-by-step guide on how I re-created a chart from NPR with ggplot2.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2020-05-24",
    "categories": [
      "data visualization",
      "data wrangling",
      "tutorial",
      "fredr",
      "ggplot2"
    ],
    "contents": "\r\nEarlier this month, I came across a striking chart from NPR that showed the historic in employment in April 2020 due to COVID-19:\r\nSource: NPR\r\nThe chart does an excellent job of relaying how historic the drop in payroll was by highlighting the periods of economic recession and adding text labels so that the reader can easily put the drop into historical perspective.\r\nIdea for Blog Series\r\nThe chart from NPR inspired me to start a blog series where I try to re-create data visualizations I come across on the internet and share my process with others.\r\nThis is part one in the series with more to come later.\r\nAcquiring the Data\r\nThe Total Nonfarm Payroll data is available from the Federal Reserve Bank of St. Louis through it’s Federal Reserve Economic Data (FRED) database.\r\nLoading the data in R is easy thanks to the fredr package which allows you to fetch data from the FRED API.\r\n\r\n\r\nShow code\r\n\r\nlibrary(fredr)\r\n\r\n\r\n\r\nIn order to connect to the FRED API, you need to first obtain a FRED API key. Once you have a key, replace the “FRED_API_KEY” below with your key number and you will be granted access to the FRED database.\r\n\r\n\r\nShow code\r\n\r\nfredr_set_key(FRED_API_KEY)\r\n\r\n\r\n\r\nThe Total Nonfarm Payroll series we want to load is called PAYEMS.\r\nIn the code below, we just need to specify the series name and include units = \"chg\" in order to get the month-to-month change:\r\n\r\n\r\nShow code\r\n\r\nfredr(series_id = \"PAYEMS\", units = \"chg\")\r\n\r\n\r\n# A tibble: 989 x 5\r\n   date       series_id value realtime_start realtime_end\r\n   <date>     <chr>     <dbl> <date>         <date>      \r\n 1 1939-01-01 PAYEMS       NA 2021-06-10     2021-06-10  \r\n 2 1939-02-01 PAYEMS      177 2021-06-10     2021-06-10  \r\n 3 1939-03-01 PAYEMS      180 2021-06-10     2021-06-10  \r\n 4 1939-04-01 PAYEMS     -186 2021-06-10     2021-06-10  \r\n 5 1939-05-01 PAYEMS      205 2021-06-10     2021-06-10  \r\n 6 1939-06-01 PAYEMS      203 2021-06-10     2021-06-10  \r\n 7 1939-07-01 PAYEMS      -83 2021-06-10     2021-06-10  \r\n 8 1939-08-01 PAYEMS      244 2021-06-10     2021-06-10  \r\n 9 1939-09-01 PAYEMS      368 2021-06-10     2021-06-10  \r\n10 1939-10-01 PAYEMS      380 2021-06-10     2021-06-10  \r\n# ... with 979 more rows\r\n\r\nThe first observation in dataset above, January 1939, contains a missing value since we pulled the month-to-month change and this was the first month in the series.\r\nIn the code below, we can replace the NA with 0 by using replace(is.na(.), 0) and create a new column called color_assign that assigns the color black to values with a positive change and red to values with a negative change in order to match the colors used within the NPR chart.\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\n\r\ndataset <- fredr(series_id = \"PAYEMS\", units = \"chg\") %>% \r\n           filter(date <= \"2020-04-01\") %>% \r\n           replace(is.na(.), 0) %>% \r\n           mutate(value = value/1000,\r\n                  color_assign = ifelse(value > 0, \"black\", \r\n                                 ifelse(value == 0, \"grey\", \"red\")))\r\n\r\n\r\n\r\n\r\nCreating the Chart\r\nThe package we will use to create the chart is the ggplot2 package.\r\nLet’s start by making a basic plot of the dataset:\r\n\r\n\r\nShow code\r\n\r\nggplot(data = dataset, \r\n       aes(x = date, y = value, colour = color_assign, fill = color_assign)) +\r\n  # Add columns to plot\r\n  geom_col(width = 1) +\r\n  theme_minimal()\r\n\r\n\r\n\r\n\r\nAs you can see, the color_assign column we created earlier matched the names of the colors to the values correctly, but did not match the colors themselves correctly. This is because the ggplot2 package assigns the colors to categories by default, but no worries, as we can change this by manually assigning the colors as shown below:\r\n\r\n\r\nShow code\r\n\r\nggplot(data = dataset, \r\n       aes(x = date, y = value, colour = color_assign, fill = color_assign)) +\r\n  geom_col(width = 1) +\r\n  # Assign black, grey, and red colors\r\n  scale_colour_manual(values = c(\"#333333\",\"#EBEBEB\",\"#D8472B\")) +\r\n  scale_fill_manual(values = c(\"#333333\",\"#EBEBEB\",\"#D8472B\")) +\r\n  theme_minimal()\r\n\r\n\r\n\r\n\r\nAdding Recession Periods\r\nIn order to add the grey U.S. recession periods in the NPR chart, we first need to define the start and end dates of each recession.\r\nThe recession dates are available from FRED here dating back to the first recorded U.S. recession in 1857. Since our dataset starts in 1939, we just need the recession periods from everything past that date and we can put them into a table like so below:\r\n\r\n\r\nShow code\r\n\r\nrecession_periods = read.table(textConnection(\r\n  \"Start, End\r\n  1945-02-01, 1945-10-01\r\n  1948-11-01, 1949-10-01\r\n  1953-07-01, 1954-05-01\r\n  1957-08-01, 1958-04-01\r\n  1960-04-01, 1961-02-01\r\n  1969-12-01, 1970-11-01\r\n  1973-11-01, 1975-03-01\r\n  1980-01-01, 1980-07-01\r\n  1981-07-01, 1982-11-01\r\n  1990-07-01, 1991-03-01\r\n  2001-03-01, 2001-11-01\r\n  2007-12-01, 2009-06-01\"), sep=',',\r\n  colClasses=c('Date','Date'), header=TRUE)\r\n\r\nrecession_periods\r\n\r\n\r\n        Start        End\r\n1  1945-02-01 1945-10-01\r\n2  1948-11-01 1949-10-01\r\n3  1953-07-01 1954-05-01\r\n4  1957-08-01 1958-04-01\r\n5  1960-04-01 1961-02-01\r\n6  1969-12-01 1970-11-01\r\n7  1973-11-01 1975-03-01\r\n8  1980-01-01 1980-07-01\r\n9  1981-07-01 1982-11-01\r\n10 1990-07-01 1991-03-01\r\n11 2001-03-01 2001-11-01\r\n12 2007-12-01 2009-06-01\r\n\r\nNow, we can add the recession periods to our plot using the geom_rect function and assigning a grey color code to it. Please note that the order of the below code matters. Since we want the recession periods to be displayed behind our data values, it needs to come before we call geom_col or else it will be blocking the month-to-month change columns.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = dataset, \r\n       aes(x = date, y = value, colour = color_assign, fill = color_assign)) +\r\n  # Add grey bars for recession periods \r\n  geom_rect(data = recession_periods, inherit.aes = FALSE, aes(xmin = Start, xmax = End, ymin = -Inf, ymax = +Inf), fill = '#EBEBEB') +\r\n  geom_col(width = 1) +\r\n  scale_colour_manual(values = c(\"#333333\",\"#EBEBEB\",\"#D8472B\")) +\r\n  scale_fill_manual(values = c(\"#333333\",\"#EBEBEB\",\"#D8472B\")) +\r\n  theme_minimal()\r\n\r\n\r\n\r\n\r\nCleaning up the Axes and Theme\r\nNow that we have the data plotted, we need to match the aesthetics of the NPR chart. This includes adjusting the axes and removing the vertical lines and legend in our current plot.\r\nIn order to adjust the axes, we need to first assign the limits for both below:\r\n\r\n\r\nShow code\r\n\r\n# Assign limits for the y axis (in millions)\r\nylab <- c(-20,-15,-10,-5,0)\r\n\r\n# Change the x axis date range to display every 10 years\r\ncustom_breaks <- c(min(dataset$date),\r\n                   seq(from = as.Date(\"1940-01-01\"), \r\n                       to = as.Date(\"2020-01-01\"),\r\n                       by = \"10 years\"),\r\n                   max(dataset$date))\r\n\r\n\r\n\r\nIn the code below, we’re able to add the word “million” to the y axis label within scale_y_continuous and use scale_x_date to display the custom_breaks correctly on the x axis.\r\nWe also call a number of arguments within theme, such as panel.grid.major.x = element_blank(), which removes the vertical lines seen on the plot above.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = dataset, \r\n       aes(x = date, y = value, colour = color_assign, fill = color_assign)) +\r\n  geom_rect(data = recession_periods, inherit.aes = FALSE, aes(xmin = Start, xmax = End, ymin = -Inf, ymax = +Inf), fill = '#EBEBEB') +\r\n  geom_col(width = 1) +\r\n  scale_colour_manual(values = c(\"#333333\",\"#EBEBEB\",\"#D8472B\")) +\r\n  scale_fill_manual(values = c(\"#333333\",\"#EBEBEB\",\"#D8472B\")) +\r\n  # Add the word 'million' to the y axis labels\r\n  scale_y_continuous(labels = ifelse(ylab == 0, ylab, paste0(ylab, ' million'))) +\r\n  # Display dates on x axis by every 10 years\r\n  scale_x_date(breaks = custom_breaks, labels = c(\"\", seq(\"1940\",\"2020\", by=10), \"\"), expand = c(0,0,0.08,0)) +\r\n  theme_minimal() +\r\n  # Clean up aesthetics of chart\r\n  theme(legend.position = \"none\",\r\n        axis.line.x = element_line(size = 0.5, colour = \"grey\"),\r\n        axis.ticks.x = element_line(colour = \"grey\"),\r\n        axis.ticks.length.x = unit(0.15, \"cm\"),\r\n        axis.text.x = element_text(size = 8),\r\n        axis.text.y = element_text(size = 8),\r\n        panel.grid.minor = element_blank(),\r\n        panel.grid.major.x = element_blank()) +\r\n  # Remove 'date' and 'value' axis labels\r\n  labs(x = \"\", y = \"\")\r\n\r\n\r\n\r\n\r\nAdding Text Labels\r\nThe only thing left to do is add the text labels to the plot.\r\nEach label on the NPR chart has a small dot to show exactly where the text label is pointing out. We can add these dots by using geom_point and then add the text to each dot using geom_point and filtering for each date NPR called out.\r\n\r\n\r\nShow code\r\n\r\nggplot(data = dataset, \r\n       aes(x = date, y = value, colour = color_assign, fill = color_assign)) +\r\n  geom_rect(data = recession_periods, inherit.aes = FALSE, aes(xmin = Start, xmax = End, ymin = -Inf, ymax = +Inf), fill = '#EBEBEB') +\r\n  geom_col(width = 1) +\r\n  # Add red dots to large negative values\r\n  geom_point(data = .%>% filter(date %in% as.Date(c(\"1945-09-01\",\"1956-07-01\",\"1974-12-01\",\"2009-03-01\",\"2020-04-01\"))), shape = 21, colour = \"white\", fill = \"#D8472B\", size = 2) +\r\n  # Add black dot to large poisitive values\r\n  geom_point(data = .%>% filter(date %in% as.Date(\"1983-09-01\")), shape = 21, colour = \"white\", fill = \"#333333\", size = 2) +\r\n  # Add text lable for April 2020\r\n  geom_text(data = .%>% filter(date == max(date)), aes(label = paste0(\"April 2020\\n \", round(value,1),\"M\"), fontface = 2), vjust = -0.01, hjust = -0.15,  size = 3.2, color = \"#D8472B\", family = \"Arial\") +\r\n  # Add text lable for September 1945\r\n  geom_text(data = .%>% filter(date == \"1945-09-01\"), aes(label = paste0(\"Sept. 1945\\n\", round(value,1),\"M\")), vjust = 1.2, hjust = 0.05, size = 3, color = \"#363636\", family = \"Arial\") +\r\n  # Add text lable for July 1956\r\n  geom_text(data = .%>% filter(date == \"1956-07-01\"), aes(label = paste0(\"July 1956\\n\", round(value*1000,1),\"K\")), vjust = 1.2, hjust = -0.1, size = 3, color = \"#363636\", family = \"Arial\") +\r\n  # Add text lable for December 1974\r\n  geom_text(data = .%>% filter(date == \"1974-12-01\"), aes(label = paste0(\"Dec. 1974\\n\", round(value*1000,1),\"K\")), vjust = 1.2, hjust = -0.05, size = 3, color = \"#363636\", family = \"Arial\") +\r\n  # Add text lable for September 1983\r\n  geom_text(data = .%>% filter(date == \"1983-09-01\"), aes(label = paste0(\"Sept. 1983\\n+\", round(value,1),\"M\")), vjust = -0.15, hjust = 0.1, size = 3, color = \"#363636\", family = \"Arial\") +\r\n  # Add text lable for March 2009\r\n  geom_text(data = .%>% filter(date == \"2009-03-01\"), aes(label = paste0(\"March 2009\\n\", round(value*1000,1),\"K\")), vjust = 1.2, hjust = -0.05, size = 3, color = \"#363636\", family = \"Arial\") +\r\n  # Add text lable for Great Recession\r\n  geom_text(data = .%>% filter(date == \"2008-10-01\"), aes(label = \"Great\\nRecession\", fontface = 3), vjust = -1.5, size = 3.2, color = \"#363636\", family = \"Arial\") +\r\n  scale_colour_manual(values = c(\"#333333\",\"#EBEBEB\",\"#D8472B\")) +\r\n  scale_fill_manual(values = c(\"#333333\",\"#EBEBEB\",\"#D8472B\")) +\r\n  scale_y_continuous(labels = ifelse(ylab == 0, ylab, paste0(ylab, ' million'))) +\r\n  scale_x_date(breaks = custom_breaks, labels = c(\"\", seq(\"1940\",\"2020\", by=10), \"\"), expand = c(0,0,0.08,0)) +\r\n  theme_minimal() +\r\n  theme(legend.position = \"none\",\r\n        axis.line.x = element_line(size = 0.5, colour = \"grey\"),\r\n        axis.ticks.x = element_line(colour = \"grey\"),\r\n        axis.ticks.length.x = unit(0.15, \"cm\"),\r\n        axis.text.x = element_text(size = 8),\r\n        axis.text.y = element_text(size = 8),\r\n        panel.grid.minor = element_blank(),\r\n        panel.grid.major.x = element_blank()) +\r\n  labs(x = \"\", y = \"\")\r\n\r\n\r\n\r\nFinal Result\r\n\r\nAnd there’s our final result. Here’s the plot from NPR again for reference. May not be an exact match but it’s pretty close!\r\n\r\nThank you for following along and stay tuned for more attempts to re-create data visualizations seen on the internet!\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-09-re-creating-a-chart-from-npr-with-ggplot2/img/source_payroll_plot.PNG",
    "last_modified": "2021-06-10T15:39:35-04:00",
    "input_file": {},
    "preview_width": 752,
    "preview_height": 526
  },
  {
    "path": "posts/welcome/",
    "title": "Creating Interactive Maps in R",
    "description": "This post shows you how to create interactive maps in R using the {highcharter} package.",
    "author": [
      {
        "name": "Kyle Cuilla",
        "url": {}
      }
    ],
    "date": "2020-04-05",
    "categories": [
      "data visualization",
      "tutorial",
      "highcharter"
    ],
    "contents": "\r\nWhy Interactive Maps?\r\nStatic maps are an effective visual tool that communicate geographic data in an interpretive way that is generally lost if that data is only viewed in a spreadsheet.\r\nAdding interactivity to a map further improves data interpretability by allowing users to:\r\nExplore the data by zooming in on areas of interest\r\nChoose what data values to be displayed or excluded\r\nHover over an area of interest and get additional info/the exact value that’s being displayed\r\nInteractive Choropleth Map\r\nThe first interactive map I will show you how to create is a population density map by county for the state of Texas made with the highcharter package.\r\n\r\nPrerequisites\r\nBefore we get started, you will need to load highcharter and the rest of the following packages:\r\n\r\n\r\nlibrary(highcharter)\r\nlibrary(data.table)\r\nlibrary(dplyr)\r\nlibrary(RColorBrewer)\r\nlibrary(tidyr)\r\n\r\n\r\n\r\nData Prep\r\nThe dataset we’ll be using is from the USDA ERS. The data is available in both xlsx and csv format. I downloaded the data in csv format and loaded the People.csv file which contains the population estimates:\r\n\r\n\r\n# Load USDA ERS dataset\r\ncounty_df <- fread(\"C:/Users/Kyle/Downloads/People.csv\") %>% \r\n  filter(State == 'TX')\r\n\r\n\r\n\r\nThe dataset contains FIPS codes for each county. In order to map this data, we will need to join it to the dataset containing the geographic information for each county from the highcharter package.\r\n\r\n\r\n# Load Texas county map\r\ntx_counties <- get_data_from_map(download_map_data(\"countries/us/us-tx-all\"))\r\n\r\nglimpse(tx_counties)\r\n\r\n\r\nRows: 254\r\nColumns: 7\r\n$ `hc-group`    <chr> \"admin2\", \"admin2\", \"admin2\", \"admin2\", \"ad...\r\n$ `hc-middle-x` <dbl> 0.50, 0.50, 0.50, 0.50, 0.50, 0.52, 0.36, 0...\r\n$ `hc-middle-y` <dbl> 0.50, 0.50, 0.50, 0.50, 0.77, 0.50, 0.36, 0...\r\n$ `hc-key`      <chr> \"us-tx-179\", \"us-tx-393\", \"us-tx-311\", \"us-...\r\n$ `hc-a2`       <chr> \"GR\", \"RO\", \"MC\", \"DU\", \"LO\", \"LE\", \"HO\", \"...\r\n$ fips          <chr> \"48179\", \"48393\", \"48311\", \"48131\", \"48297\"...\r\n$ name          <chr> \"Gray\", \"Roberts\", \"McMullen\", \"Duval\", \"Li...\r\n\r\nBefore joining the datasets, we need to calculate the population density for 2018. We can do this by using mutate from the dplyr package to create a column called ‘density’ and divide the ‘TotalPopEst2018’ column by the ‘LandAreaSQMiles2010’ column as shown below:\r\n\r\n\r\n# Calculate population density\r\ndensity_df <- county_df %>% \r\n  select(c(fips=FIPS,County,TotalPopEst2018,LandAreaSQMiles2010)) %>%\r\n  mutate(density = round(TotalPopEst2018/LandAreaSQMiles2010,0))\r\n\r\nhead(density_df)\r\n\r\n\r\n    fips   County TotalPopEst2018 LandAreaSQMiles2010 density\r\n1: 48000    Texas        28701845           261231.71     110\r\n2: 48001 Anderson           58057             1062.60      55\r\n3: 48003  Andrews           18128             1500.71      12\r\n4: 48005 Angelina           87092              797.78     109\r\n5: 48007  Aransas           23792              252.07      94\r\n6: 48009   Archer            8786              903.11      10\r\n\r\nCreating the Map\r\nUsing the hcmap function from highcharter, we can create a basic interactive map like this one:\r\n\r\n\r\n# Create interactive map of Texas counties\r\ndensity_map <- hcmap(map = \"countries/us/us-tx-all\", \r\n      data = density_df, \r\n      value = \"density\", \r\n      joinBy = c(\"fips\"))  %>%\r\n  hc_mapNavigation(enabled = TRUE)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nCustomizing the Map\r\nIn the map above, the counties with the highest population densities clearly stand out. However, it is difficult to distinguish the differences between the counties with lower population densities.\r\nIn order to correct this, we can assign color breaks to the data by utilizing the hc_colorAxis function and assigning a color palette from the RColorBrewer package:\r\n\r\n\r\n# Add color classes and legend to map\r\ndensity_map <- hcmap(\r\n  map = \"countries/us/us-tx-all\",\r\n  data = density_df,\r\n  value = \"density\",\r\n  joinBy = c(\"fips\"),\r\n  borderWidth = 0.3\r\n)  %>%\r\n  hc_mapNavigation(enabled = TRUE) %>%\r\n  hc_legend(layout = \"vertical\",\r\n            align = \"right\",\r\n            valueDecimals = 0) %>% \r\n  hc_colorAxis(dataClasses = color_classes(\r\n    breaks = c(0, 5, 10, 25, 50, 100, 1000, 2000, 3000, 3500),\r\n    colors = c(\"#FECE91\",\"#FE9F6D\",\"#F76F5C\",\"#DE4968\",\"#B63679\",\"#8C2981\",\"#641A80\",\"#3B0F70\",\"#150E37\")\r\n  ))\r\n\r\n\r\n\r\nThe next thing we will need to do is modify what is displayed when you hover (or click if you are viewing on a mobile device) on a particular county.\r\n\r\n\r\n# Add custom tooltip to map\r\ndensity_map <- density_map %>%\r\n  hc_tooltip(\r\n    headerFormat = \"\",\r\n    pointFormat = \"{point.name}: {point.value}\",\r\n    valueDecimals = 0\r\n  )\r\n\r\n\r\n\r\nNow, the only thing left is to add a title and source to the map which we can do with the hc_title and hc_credits options:\r\n\r\n\r\n# Add title and credits to map\r\ndensity_map <- density_map %>%\r\n  hc_title(text = \"Population Density by County, 2018\") %>%\r\n  hc_credits(enabled = TRUE,\r\n             text = \"Author: Kyle Cuilla, Data: USDA ERS\",\r\n             href = \"https://www.ers.usda.gov/data-products/atlas-of-rural-and-small-town-america/download-the-data/\")\r\n\r\n\r\n\r\nAnd here is our final result!\r\n\r\n\r\n\r\n\r\nAnimated Choropleth Map\r\nSo now we have our map that displays the population density by county in 2018.\r\nLet’s say that we want to see how the population density has changed over time. How would we go about doing this?\r\nWell, we could create nine separate maps (one for each year from 2010 to 2018), but this would take up a lot of space and because the maps would each be separate, and because each map would be separate, it may be difficult to detect subtle difference between each year.\r\nTo solve these issues, we can create an animated map instead.\r\n\r\n\r\n\r\n\r\nData Prep\r\nThe county_df dataset we’ve been using contains estimated populations for each year.\r\nWe can calculate the population densities for each of these years by creating a function called ‘pop_density’ and applying it to each population estimate.\r\nWe can then use the gather function from the tidyr package to put all of the population densities into a single column called ‘density’ and all of the years into a single column called ‘years’.\r\n\r\n\r\n# Calculate population density for each year in dataset\r\npop_density <- function(x) {\r\n  round(x / county_df$LandAreaSQMiles2010, 0)\r\n}\r\n\r\ndensity_df_by_year <- county_df %>%\r\n  select(\r\n    c(\r\n      FIPS,\r\n      State,\r\n      County,\r\n      '2010' = TotalPopEst2010,\r\n      '2011' = TotalPopEst2011,\r\n      '2012' = TotalPopEst2012,\r\n      '2013' = TotalPopEst2013,\r\n      '2014' = TotalPopEst2014,\r\n      '2015' = TotalPopEst2015,\r\n      '2016' = TotalPopEst2016,\r\n      '2017' = TotalPopEst2017,\r\n      '2018' = TotalPopEst2018\r\n    )\r\n  ) %>%\r\n  mutate_at(vars(matches(\"201\")), pop_density) %>%\r\n  filter(State == 'TX') %>%\r\n  gather(year, density, -c(FIPS, State, County)) %>%\r\n  mutate(fips = ifelse(nchar(FIPS) < 5, paste0(\"0\", FIPS), FIPS)) %>%\r\n  filter(!grepl('000', FIPS),!State == 'US')\r\n\r\nhead(density_df_by_year)\r\n\r\n\r\n   FIPS State    County year density  fips\r\n1 48001    TX  Anderson 2010      55 48001\r\n2 48003    TX   Andrews 2010      10 48003\r\n3 48005    TX  Angelina 2010     109 48005\r\n4 48007    TX   Aransas 2010      92 48007\r\n5 48009    TX    Archer 2010      10 48009\r\n6 48011    TX Armstrong 2010       2 48011\r\n\r\nThe animated highcarter map needs the population densities in a single list called ‘sequence’ in order to work properly. We can create the list of densities by using the list_parse function:\r\n\r\n\r\n# Create list column containing population densities by year \r\ndensity_df_seq <- density_df_by_year %>%\r\n  group_by(fips) %>%\r\n  do(sequence = list_parse(select(., value = density)))\r\n\r\nhead(density_df_seq)\r\n\r\n\r\n# A tibble: 6 x 2\r\n# Rowwise: \r\n   fips sequence  \r\n  <int> <list>    \r\n1 48001 <list [9]>\r\n2 48003 <list [9]>\r\n3 48005 <list [9]>\r\n4 48007 <list [9]>\r\n5 48009 <list [9]>\r\n6 48011 <list [9]>\r\n\r\nYou can see in the output we have a column containing the FIPS codes for each county and a list of length 9 which contains one population density value for each year from 2010 to 2018.\r\nNext, we need to join this dataset back to the original dataset so that we have the county names, years, and population densities all in one dataset:\r\n\r\n\r\n# Join with original dataset\r\ndensity_df_by_year <- left_join(density_df_by_year,density_df_seq)\r\n\r\nhead(density_df_by_year)\r\n\r\n\r\n   FIPS State    County year density  fips\r\n1 48001    TX  Anderson 2010      55 48001\r\n2 48003    TX   Andrews 2010      10 48003\r\n3 48005    TX  Angelina 2010     109 48005\r\n4 48007    TX   Aransas 2010      92 48007\r\n5 48009    TX    Archer 2010      10 48009\r\n6 48011    TX Armstrong 2010       2 48011\r\n                                     sequence\r\n1          55, 55, 55, 55, 54, 54, 54, 55, 55\r\n2          10, 10, 11, 11, 12, 12, 12, 12, 12\r\n3 109, 109, 110, 109, 110, 110, 110, 110, 109\r\n4        92, 92, 93, 95, 97, 98, 100, 101, 94\r\n5          10, 10, 10, 10, 10, 10, 10, 10, 10\r\n6                   2, 2, 2, 2, 2, 2, 2, 2, 2\r\n\r\nCreating the Map\r\nTo create the animated map, all we need to do is take the existing density_map that we created and update the dataset from density_df to density_df_by_year\r\n\r\n\r\n# Create interactive map of Texas counties\r\nanimated_map <- hcmap(\r\n  map = \"countries/us/us-tx-all\",\r\n  data = density_df_by_year,\r\n  value = \"density\",\r\n  joinBy = c(\"fips\"),\r\n  borderWidth = 0.3\r\n)  %>%\r\n  hc_mapNavigation(enabled = TRUE) %>%\r\n  hc_colorAxis(dataClasses = color_classes(\r\n    breaks = c(0, 5, 10, 25, 50, 100, 1000, 2000, 3000, 3500),\r\n    colors = c(\"#FECE91\",\"#FE9F6D\",\"#F76F5C\",\"#DE4968\",\"#B63679\",\"#8C2981\",\"#641A80\",\"#3B0F70\",\"#150E37\")\r\n  )) %>%\r\n  hc_legend(layout = \"vertical\",\r\n            align = \"right\",\r\n            valueDecimals = 0) %>%\r\n  hc_tooltip(\r\n    headerFormat = \"\",\r\n    pointFormat = \"{point.name}: {point.value}\",\r\n    valueDecimals = 0\r\n  ) %>%\r\n  hc_title(text = \"Population Density by County, 2010 to 2018\") %>%\r\n  hc_credits(enabled = TRUE,\r\n             text = \"Author: Kyle Cuilla, Data: USDA ERS\",\r\n             href = \"https://www.ers.usda.gov/data-products/atlas-of-rural-and-small-town-america/download-the-data/\")  \r\n\r\n\r\n\r\nAnd then add the hc_motion option to the map:\r\n\r\n\r\n# Add animation to map\r\nanimated_map <- animated_map %>%\r\n  hc_motion(\r\n    enabled = TRUE,\r\n    series = 0,\r\n    autoPlay = TRUE,\r\n    loop = TRUE,\r\n    labels = unique(density_df_by_year$year)\r\n  )\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/welcome/img/map_preview.PNG",
    "last_modified": "2021-06-10T15:27:00-04:00",
    "input_file": {},
    "preview_width": 692,
    "preview_height": 494
  }
]
